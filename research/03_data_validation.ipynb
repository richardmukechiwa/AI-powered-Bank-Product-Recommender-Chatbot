{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "afaa322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a1c19ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\RICH-FILES\\\\Desktop\\\\ml\\\\AI-powered-Bank-Product-Recommender-Chatbot'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\RICH-FILES\\\\Desktop\\\\ml'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f3a454a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = \"C:/Users/RICH-FILES/Desktop/ml/AI-powered-Bank-Product-Recommender-Chatbot\"\n",
    "os.chdir(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataValidationConfig:\n",
    "    val_root_dir: Path\n",
    "    STATUS_FILE: str\n",
    "    customer_data: Path\n",
    "    all_schema: dict\n",
    "    customer_data: Path\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a096c8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BankProducts.constants import *\n",
    "from BankProducts.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_data_validation_config(self) -> DataValidationConfig:\n",
    "        config = self.config.data_validation\n",
    "        schema = self.schema.COLUMNS\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "        data_validation_config = DataValidationConfig(\n",
    "            val_root_dir=Path(config.val_root_dir),\n",
    "            STATUS_FILE=Path(config.STATUS_FILE),\n",
    "            customer_data=Path(config.customer_data),\n",
    "            all_schema=schema,\n",
    "        )\n",
    "\n",
    "        return data_validation_config\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from BankProducts import  logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310f0987",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataValidation:\n",
    "    def __init__(self, config: DataValidationConfig):\n",
    "        self.config = config\n",
    "        logger.info(f\"Data Validation started \")\n",
    "        \n",
    "    def validate_all_columns(self) -> bool:\n",
    "        try:\n",
    "            data = pd.read_csv(self.config.customer_data)\n",
    "            logger.info(f\"Data loaded from {self.config.customer_data}\")\n",
    "            \n",
    "            # convert the Transaction Date column to datetime format\n",
    "            data['transactiondate'] = pd.to_datetime(data['transactiondate'])\n",
    "            # Check if the data is empty\n",
    "            logger.info(f\"Checking if data is empty\")                       \n",
    "            if data.empty:          \n",
    "                return False\n",
    "            logger.info(f\"Data loaded successfully with {data.shape[0]} rows and {data.shape[1]} columns\")      \n",
    "            # Check if all required columns are present                     \n",
    "            \n",
    "            \n",
    "            if data.empty:\n",
    "                raise ValueError(\"Customer data is empty.\")\n",
    "            all_cols = set(data.columns)\n",
    "            all_schema = set(self.config.all_schema.keys())\n",
    "            logger.info(f\"Columns in data: {all_cols}\")\n",
    "\n",
    "            # Check for missing columns in data\n",
    "            missing_in_data = all_schema - all_cols\n",
    "            \n",
    "            # Check for extra columns in data\n",
    "            extra_in_data = all_cols - all_schema\n",
    "            logger.info(f\"checking for missing columns in data: {missing_in_data}\")\n",
    "\n",
    "            validation_status = True\n",
    "            if missing_in_data or extra_in_data:\n",
    "                validation_status = False\n",
    "                logger.error(f\"Missing columns in data: {missing_in_data}\")\n",
    "\n",
    "            with open(self.config.STATUS_FILE, 'w') as f:\n",
    "                f.write(f\"Validation status: {validation_status}\\n\")\n",
    "                if missing_in_data:\n",
    "                    f.write(f\"Missing columns in data: {missing_in_data}\\n\")\n",
    "                if extra_in_data:\n",
    "                    f.write(f\"Extra columns in data: {extra_in_data}\\n\")\n",
    "\n",
    "            logger.info(f\"All columns validation status: {validation_status}\")\n",
    "            return validation_status\n",
    "\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    \n",
    "    def validate_all_column(self)-> bool:\n",
    "        try:\n",
    "            validation_status = None\n",
    "\n",
    "            data = pd.read_csv(self.config.customer_data)\n",
    "            all_cols = list(data.columns)\n",
    "\n",
    "            all_schema = self.config.all_schema.keys()\n",
    "\n",
    "            \n",
    "            for col in all_cols:\n",
    "                if col not in all_schema:\n",
    "                    validation_status = False\n",
    "                    with open(self.config.STATUS_FILE, 'w') as f:\n",
    "                        f.write(f\"Validation status: {validation_status}\")\n",
    "                else:\n",
    "                    validation_status = True\n",
    "                    with open(self.config.STATUS_FILE, 'w') as f:\n",
    "                        f.write(f\"Validation status: {validation_status}\")\n",
    "\n",
    "            return validation_status\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise e\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cb775a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-02 23:27:19,962: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-06-02 23:27:19,972: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-06-02 23:27:19,979: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2025-06-02 23:27:19,982: INFO: common: created directory at: artifacts]\n",
      "[2025-06-02 23:27:19,985: INFO: common: created directory at: artifacts]\n",
      "[2025-06-02 23:27:19,987: INFO: 1370065407: Data Validation started ]\n",
      "[2025-06-02 23:27:20,151: INFO: 1370065407: Data loaded from artifacts\\data_ingestion\\customer_data.csv]\n",
      "Validation failed: 'Transactiondate'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_validation_config = config.get_data_validation_config()\n",
    "    \n",
    "    # Validate CSV files\n",
    "    data_validation = DataValidation(config=data_validation_config)\n",
    "    data_validation.validate_all_columns()\n",
    "    data_validation.validate_all_column()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Validation failed: {e}\")\n",
    "# The code above is a complete example of how to validate the existence and content of CSV files and database tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 19 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   transactionid       20000 non-null  int64  \n",
      " 1   customerid          20000 non-null  int64  \n",
      " 2   transactiondate     20000 non-null  object \n",
      " 3   transactiontype     20000 non-null  object \n",
      " 4   amount              20000 non-null  float64\n",
      " 5   productcategory     20000 non-null  object \n",
      " 6   productsubcategory  20000 non-null  object \n",
      " 7   branchcity          20000 non-null  object \n",
      " 8   branchlat           20000 non-null  float64\n",
      " 9   branchlong          20000 non-null  float64\n",
      " 10  channel             20000 non-null  object \n",
      " 11  currency            20000 non-null  object \n",
      " 12  creditcardfees      20000 non-null  float64\n",
      " 13  insurancefees       20000 non-null  float64\n",
      " 14  latepaymentamount   20000 non-null  float64\n",
      " 15  customerscore       20000 non-null  int64  \n",
      " 16  monthlyincome       20000 non-null  float64\n",
      " 17  customersegment     20000 non-null  object \n",
      " 18  recommendedoffer    20000 non-null  object \n",
      "dtypes: float64(7), int64(3), object(9)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_validation_config.customer_data)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bankprod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
