{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7deb0443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e57277e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\RICH-FILES\\\\Desktop\\\\ml\\\\AI-powered-Bank-Product-Recommender-Chatbot'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "66d4e239",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(\"../.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dd0303c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\RICH-FILES\\\\Desktop\\\\ml'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d241dbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = \"C:/Users/RICH-FILES/Desktop/ml/AI-powered-Bank-Product-Recommender-Chatbot\"\n",
    "os.chdir(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    \"\"\"\n",
    "    Data Transformation Configuration\n",
    "    \"\"\"\n",
    "    root_dir: Path\n",
    "    transformed_data_file: Path\n",
    "    customer_path: Path\n",
    "    product_path: Path\n",
    "    train_data_file: Path\n",
    "    test_data_file: Path\n",
    "    target_column: str\n",
    "    joined_data_file: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BankProducts.constants import *\n",
    "from BankProducts.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2fc534cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,    \n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH,\n",
    "        ):\n",
    "       \n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)        \n",
    "    \n",
    "        create_directories([self.config.artifacts_root])\n",
    "        \n",
    "    def get_data_transformation_config(self)-> DataTransformationConfig:\n",
    "        \"\"\"\n",
    "        Returns Data Transformation Configuration\n",
    "        \"\"\"\n",
    "        config = self.config.data_transformation\n",
    "        schema =  self.schema.target_column\n",
    "        \n",
    "        create_directories([self.config.artifacts_root])\n",
    "        \n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            transformed_data_file= Path(config.transformed_data_file),\n",
    "            product_path= Path(config.product_path),\n",
    "            customer_path= Path(config.customer_path),\n",
    "            train_data_file= Path(config.train_data_file),\n",
    "            test_data_file= Path(config.test_data_file),\n",
    "            target_column= schema.name,\n",
    "            joined_data_file= Path(config.joined_data_file)\n",
    "            )\n",
    "        \n",
    "        \n",
    "        return data_transformation_config\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5c6cf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import os  \n",
    "from BankProducts import logger\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf694c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "        #self.data = None\n",
    "        #self.transformed_data = None\n",
    "        \n",
    "    def join_datasets(self):\n",
    "        \"\"\"\n",
    "        Join customer and product datasets\"\"\"    \n",
    "        try:\n",
    "            customer_data = pd.read_csv(self.config.customer_path)\n",
    "            product_data = pd.read_csv(self.config.product_path)\n",
    "\n",
    "            # Ensure the directory for saving exists\n",
    "            output_dir = os.path.dirname(self.config.transformed_data_file)\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            \n",
    "            #print(customer_data['occupation'].unique()) # Check unique occupations\n",
    "            \n",
    "            \n",
    "            \n",
    "            def group_occupation(job):\n",
    "                job = job.lower()\n",
    "\n",
    "                if any(keyword in job for keyword in [\n",
    "                    'engineer', 'architect', 'developer', 'planner', 'technologist',\n",
    "                    'surveyor', 'scientist', 'analyst', 'chemist', 'mudlogger'\n",
    "                ]):\n",
    "                    return 'Engineering'\n",
    "\n",
    "                elif any(keyword in job for keyword in [\n",
    "                    'doctor', 'physiotherapist', 'oncologist', 'therapist', 'psychotherapist',\n",
    "                    'homeopath', 'geneticist', 'embryologist', 'hospital', 'health',\n",
    "                    'clinical', 'radiation', 'occupational', 'medical', 'pharmacist'\n",
    "                ]):\n",
    "                    return 'Healthcare'\n",
    "\n",
    "                elif any(keyword in job for keyword in [\n",
    "                    'teacher', 'lecturer', 'education', 'instructor', 'tutor', 'educational'\n",
    "                ]):\n",
    "                    return 'Education'\n",
    "\n",
    "                elif any(keyword in job for keyword in [\n",
    "                    'designer', 'artist', 'illustrator', 'ceramics', 'furniture', 'product designer',\n",
    "                    'fashion', 'graphic', 'web', 'interior', 'fine artist', 'photographer'\n",
    "                ]):\n",
    "                    return 'Creative Design'\n",
    "\n",
    "                elif any(keyword in job for keyword in [\n",
    "                    'finance', 'financial', 'investment', 'trader', 'planner', 'cfo',\n",
    "                    'actuary', 'underwriter', 'banker', 'comptroller'\n",
    "                ]):\n",
    "                    return 'Finance'\n",
    "\n",
    "                elif any(keyword in job for keyword in [\n",
    "                    'data', 'programmer', 'software', 'it', 'systems', 'naval architect',\n",
    "                    'consultant', 'technology'\n",
    "                ]):\n",
    "                    return 'IT'\n",
    "\n",
    "                elif any(keyword in job for keyword in [\n",
    "                    'manager', 'administrator', 'officer', 'coordinator', 'executive',\n",
    "                    'secretary', 'personal assistant', 'inspector', 'broker'\n",
    "                ]):\n",
    "                    return 'Administration'\n",
    "\n",
    "                elif any(keyword in job for keyword in [\n",
    "                    'journalist', 'writer', 'editor', 'broadcaster', 'media', 'production',\n",
    "                    'television', 'film', 'radio'\n",
    "                ]):\n",
    "                    return 'Communications'\n",
    "\n",
    "                elif any(keyword in job for keyword in [\n",
    "                    'lawyer', 'barrister', 'legal', 'licensed conveyancer', 'tax', 'patent examiner'\n",
    "                ]):\n",
    "                    return 'Legal'\n",
    "\n",
    "                elif any(keyword in job for keyword in [\n",
    "                    'conservation', 'environmental', 'forester', 'nature', 'marine', 'horticulturist',\n",
    "                    'land', 'tree surgeon'\n",
    "                ]):\n",
    "                    return 'Environment'\n",
    "\n",
    "                elif any(keyword in job for keyword in [\n",
    "                    'government', 'public', 'prison', 'trading standards', 'local government'\n",
    "                ]):\n",
    "                    return 'Public Sector'\n",
    "\n",
    "                elif any(keyword in job for keyword in [\n",
    "                    'sales', 'retail', 'buyer', 'merchandiser', 'estate agent'\n",
    "                ]):\n",
    "                    return 'Marketing'\n",
    "\n",
    "                elif any(keyword in job for keyword in [\n",
    "                    'catering', 'restaurant', 'hospitality', 'hotel'\n",
    "                ]):\n",
    "                    return 'Hospitality'\n",
    "\n",
    "                elif any(keyword in job for keyword in [\n",
    "                    'volunteer', 'charity', 'community', 'development worker'\n",
    "                ]):\n",
    "                    return 'Community Work'\n",
    "\n",
    "                else:\n",
    "                    return 'Other'\n",
    "                \n",
    "            # Apply the grouping function to create a new column\n",
    "            customer_data['occupation_grouped'] = customer_data['occupation'].apply(group_occupation)\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            customer_data['existing_products'] = customer_data['existing_products'].str.split(',')  # Split the existing_products column into a list\n",
    "            \n",
    "            df_exploded = customer_data.explode('existing_products') # \n",
    "\n",
    "            # Join operation\n",
    "            joined_data = pd.merge(df_exploded, product_data, how=\"left\",\n",
    "                                left_on=\"existing_products\", right_on=\"product_name\")\n",
    "            \n",
    "            #drop unnecessary columns\n",
    "            joined_data = joined_data.drop(columns=['existing_products'], errors='ignore')  # Drop columns which are not needed if it exists\n",
    "            \n",
    "            #check the dataset head\n",
    "            print(joined_data.head())\n",
    "            \n",
    "            \n",
    "            # Save the joined data\n",
    "            try:   \n",
    "                joined_data.to_csv(self.config.joined_data_file, index=False)\n",
    "                logger.info(f\"Joined dataset saved to {self.config.joined_data_file}\")\n",
    "                print(f\"Joined dataset saved to {self.config.joined_data_file}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error saving joined dataset: {e}\")\n",
    "                print(f\"Error saving joined dataset: {e}\")\n",
    "            \n",
    "            return joined_data\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in joining datasets: {e}\")\n",
    "            print(f\"Error in joining datasets: {e}\")\n",
    "            raise e\n",
    "    def transform_data(self):\n",
    "        \"\"\"\n",
    "        Transform the data as per the requirements\n",
    "        \"\"\"\n",
    "        \n",
    "        # Load the data\n",
    "        data = pd.read_csv(self.config.joined_data_file)\n",
    "        # Perform transformations\n",
    "        print(data.head())\n",
    "        \n",
    "        print(\":\"*100)\n",
    "        \n",
    "        data.info()\n",
    "        print(\":\"*100)\n",
    "        \n",
    "        data.describe()\n",
    "        print(\":\"*100)\n",
    "        print(data.columns)\n",
    "        print(\":\"*100)\n",
    "        \n",
    "        #drop na\n",
    "        data.dropna(inplace=True\n",
    "                            )\n",
    "        #check null values\n",
    "        print(data.isnull().sum())\n",
    "        \n",
    "        #check the number of  values in the target column\n",
    "        print(data[self.config.target_column].value_counts())\n",
    "        \n",
    "        #resize the dataset to match the number of rows in the target column\n",
    "        data = data[data[self.config.target_column].notnull()]\n",
    "        \n",
    "        #drop unnecessary columns\n",
    "        data = data.drop(columns=['customer_id','name', 'eligibility', 'description', 'financial_goals', 'occupation', 'occupation_grouped'], errors='ignore')\n",
    "        \n",
    "        # print the first 5 rows of the data\n",
    "        data.head()\n",
    "        \n",
    "        #remove duplicates\n",
    "        data.drop_duplicates(inplace=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #plot \"product_name\" histogram based of gender using seaborn\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        ax = sns.histplot(data=data, x= self.config.target_column, hue='gender', multiple='stack')\n",
    "\n",
    "        # Add separated count labels above each segment\n",
    "        for container in ax.containers:\n",
    "            # Add offset so overlapping labels are vertically separated\n",
    "            for bar in container:\n",
    "                height = bar.get_height()\n",
    "                if height > 0:\n",
    "                    ax.text(\n",
    "                        bar.get_x() + bar.get_width() / 2,\n",
    "                        bar.get_y() + height / 2,  # Place label at the middle of the segment\n",
    "                        f'{int(height)}',\n",
    "                        ha='center',\n",
    "                        va='center',\n",
    "                        fontsize=9,\n",
    "                        color='white',  # or 'black' depending on your bar color\n",
    "                        weight='bold'\n",
    "                    )\n",
    "\n",
    "\n",
    "        plt.title(\"Product Name Histogram by Gender\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "                    \n",
    "        # drop the gender\n",
    "        data = data.drop(columns=['gender'])\n",
    "        \n",
    "        #plot \"age\" histogram\n",
    "        plt.figure(figsize=(10,6))\n",
    "        plt.hist(data[\"age\"], bins=10, edgecolor='black', color= \"orange\", alpha=0.7)\n",
    "        plt.title(\"Age Frequency Distribution\")\n",
    "        plt.xlabel(\"Age\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.savefig(\"age_histogram.png\")\n",
    "        \n",
    "    \n",
    "        \n",
    "        #plot \"product_name\" vs \"age\" bar plot\n",
    "        plt.figure(figsize=(10,6))\n",
    "        plt.bar(data[\"product_name\"], data[\"age\"], color=\"green\")\n",
    "        plt.title(\"Product Name vs Age Bar Plot\")\n",
    "        plt.xlabel(\"Product Name\")\n",
    "        plt.ylabel(\"Age\")\n",
    "        plt.savefig(\"product_name_vs_age_bar_plot.png\")\n",
    "        \n",
    "        #feature selection\n",
    "        # If it's a categorical variable like a string, correlation won't work correctly\n",
    "        correlation_matrix = data.select_dtypes(include= ['float64', 'int64']).corr()\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', square=True)\n",
    "        plt.title(\"Correlation Matrix\")\n",
    "        plt.show()\n",
    "        plt.savefig('correlation_matrix.png')\n",
    "    \n",
    "        # Save the data to a CSV file to the specified path\n",
    "        os.makedirs(os.path.dirname(self.config.transformed_data_file), exist_ok=True)\n",
    "        data.to_csv(self.config.transformed_data_file, index=False)\n",
    "        logger.info(f\"Transformed data saved to {self.config.transformed_data_file}\")\n",
    "        print(f\"Transformed data saved to {self.config.transformed_data_file}\")\n",
    "        \n",
    "        return data\n",
    "      \n",
    "    def split_data(self):\n",
    "        data =  pd.read_csv(self.config.transformed_data_file)  \n",
    "        \n",
    "        #  splitting data into train and test sets\n",
    "        train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # print the first 5 rows of the train and test data\n",
    "        print(\"Train Data:\")\n",
    "        print(train_data.head())\n",
    "        \n",
    "        print(\"Test Data:\") \n",
    "        print(test_data.head())\n",
    "        \n",
    "        \n",
    "        #save train_data and test_data to csv files\n",
    "        train_data.to_csv(os.path.join(self.config.train_data_file), index=False)\n",
    "        test_data.to_csv(os.path.join(self.config.test_data_file), index=False)\n",
    "        \n",
    "        logger.info(f\"Train and test sets saved to {self.config.train_data_file} and {self.config.test_data_file}\")\n",
    "        print(f\"Train and test sets saved to {self.config.train_data_file} and {self.config.test_data_file}\")\n",
    "        # Log the shapes of the train and test sets\n",
    "        logger.info(f\"Train set shape: {train_data.shape}, Test set shape: {test_data.shape}\")\n",
    "        #print the shapes of the train and test sets\n",
    "        print(f\"Train set shape: {train_data.shape}, Test set shape: {test_data.shape}\")\n",
    "        # Log the shapes of the train and test sets\n",
    "        return train_data, test_data    \n",
    "        \n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7572949b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-31 22:21:20,749: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-05-31 22:21:20,765: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-05-31 22:21:20,780: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2025-05-31 22:21:20,784: INFO: common: created directory at: artifacts]\n",
      "[2025-05-31 22:21:20,788: INFO: common: created directory at: artifacts]\n",
      "                            customer_id          name  age  gender  \\\n",
      "0  7bb08efe-5222-4698-8540-4de1f56c23bb   Marissa Roy   24  Female   \n",
      "1  7bb08efe-5222-4698-8540-4de1f56c23bb   Marissa Roy   24  Female   \n",
      "2  7bb08efe-5222-4698-8540-4de1f56c23bb   Marissa Roy   24  Female   \n",
      "3  01e4e9c0-008e-443f-a0d4-ee1e27392941  Peter Hughes   25    Male   \n",
      "4  01e4e9c0-008e-443f-a0d4-ee1e27392941  Peter Hughes   25    Male   \n",
      "\n",
      "                  occupation  annual_income marital_status  credit_score  \\\n",
      "0     Recruitment consultant       66387.36        Married           774   \n",
      "1     Recruitment consultant       66387.36        Married           774   \n",
      "2     Recruitment consultant       66387.36        Married           774   \n",
      "3  Building control surveyor       61270.47         Single           801   \n",
      "4  Building control surveyor       61270.47         Single           801   \n",
      "\n",
      "  financial_goals occupation_grouped    product_name  \\\n",
      "0          Travel                 IT  Education Loan   \n",
      "1          Travel                 IT             NaN   \n",
      "2          Travel                 IT             NaN   \n",
      "3      Retirement        Engineering   Fixed Deposit   \n",
      "4      Retirement        Engineering             NaN   \n",
      "\n",
      "                                         description  \\\n",
      "0       Loan for students pursuing higher education.   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3  Investment with fixed returns over a chosen term.   \n",
      "4                                                NaN   \n",
      "\n",
      "                                         eligibility  \n",
      "0  Age below 35 and enrollment in a valid institu...  \n",
      "1                                                NaN  \n",
      "2                                                NaN  \n",
      "3                          Minimum deposit of $1,000  \n",
      "4                                                NaN  \n",
      "[2025-05-31 22:21:24,858: INFO: 3140011670: Joined dataset saved to artifacts\\data_transformation\\joined_data.csv]\n",
      "Joined dataset saved to artifacts\\data_transformation\\joined_data.csv\n",
      "                            customer_id          name  age  gender  \\\n",
      "0  7bb08efe-5222-4698-8540-4de1f56c23bb   Marissa Roy   24  Female   \n",
      "1  7bb08efe-5222-4698-8540-4de1f56c23bb   Marissa Roy   24  Female   \n",
      "2  7bb08efe-5222-4698-8540-4de1f56c23bb   Marissa Roy   24  Female   \n",
      "3  01e4e9c0-008e-443f-a0d4-ee1e27392941  Peter Hughes   25    Male   \n",
      "4  01e4e9c0-008e-443f-a0d4-ee1e27392941  Peter Hughes   25    Male   \n",
      "\n",
      "                  occupation  annual_income marital_status  credit_score  \\\n",
      "0     Recruitment consultant       66387.36        Married           774   \n",
      "1     Recruitment consultant       66387.36        Married           774   \n",
      "2     Recruitment consultant       66387.36        Married           774   \n",
      "3  Building control surveyor       61270.47         Single           801   \n",
      "4  Building control surveyor       61270.47         Single           801   \n",
      "\n",
      "  financial_goals occupation_grouped    product_name  \\\n",
      "0          Travel                 IT  Education Loan   \n",
      "1          Travel                 IT             NaN   \n",
      "2          Travel                 IT             NaN   \n",
      "3      Retirement        Engineering   Fixed Deposit   \n",
      "4      Retirement        Engineering             NaN   \n",
      "\n",
      "                                         description  \\\n",
      "0       Loan for students pursuing higher education.   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3  Investment with fixed returns over a chosen term.   \n",
      "4                                                NaN   \n",
      "\n",
      "                                         eligibility  \n",
      "0  Age below 35 and enrollment in a valid institu...  \n",
      "1                                                NaN  \n",
      "2                                                NaN  \n",
      "3                          Minimum deposit of $1,000  \n",
      "4                                                NaN  \n",
      "::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87531 entries, 0 to 87530\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   customer_id         87531 non-null  object \n",
      " 1   name                87531 non-null  object \n",
      " 2   age                 87531 non-null  int64  \n",
      " 3   gender              87531 non-null  object \n",
      " 4   occupation          87531 non-null  object \n",
      " 5   annual_income       87531 non-null  float64\n",
      " 6   marital_status      87531 non-null  object \n",
      " 7   credit_score        87531 non-null  int64  \n",
      " 8   financial_goals     87531 non-null  object \n",
      " 9   occupation_grouped  87531 non-null  object \n",
      " 10  product_name        37591 non-null  object \n",
      " 11  description         37591 non-null  object \n",
      " 12  eligibility         37591 non-null  object \n",
      "dtypes: float64(1), int64(2), object(10)\n",
      "memory usage: 8.7+ MB\n",
      "::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "Index(['customer_id', 'name', 'age', 'gender', 'occupation', 'annual_income',\n",
      "       'marital_status', 'credit_score', 'financial_goals',\n",
      "       'occupation_grouped', 'product_name', 'description', 'eligibility'],\n",
      "      dtype='object')\n",
      "::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
      "customer_id           0\n",
      "name                  0\n",
      "age                   0\n",
      "gender                0\n",
      "occupation            0\n",
      "annual_income         0\n",
      "marital_status        0\n",
      "credit_score          0\n",
      "financial_goals       0\n",
      "occupation_grouped    0\n",
      "product_name          0\n",
      "description           0\n",
      "eligibility           0\n",
      "dtype: int64\n",
      "product_name\n",
      "Home Loan          7613\n",
      "Credit Card        7573\n",
      "Fixed Deposit      7552\n",
      "Savings Account    7463\n",
      "Education Loan     7390\n",
      "Name: count, dtype: int64\n",
      "An error occurred: Could not interpret value `gender` for `hue`. An entry with this name does not appear in `data`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    \n",
    "    data_transformation = DataTransformation(config=data_transformation_config)\n",
    "    \n",
    "    data_transformation.join_datasets()\n",
    "    data_transformation.transform_data()\n",
    "    data_transformation.split_data()\n",
    "    \n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bankprod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
