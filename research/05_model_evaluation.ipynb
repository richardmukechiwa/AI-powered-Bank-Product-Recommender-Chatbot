{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a42ec141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\RICH-FILES\\\\Desktop\\\\ml\\\\AI-powered-Bank-Product-Recommender-Chatbot'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cc54f688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\RICH-FILES\\\\Desktop\\\\ml'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0430e424",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = \"C:/Users/RICH-FILES/Desktop/ml/AI-powered-Bank-Product-Recommender-Chatbot\"\n",
    "os.chdir(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelEvaluationConfig:\n",
    "    root_dir: Path\n",
    "    test_data_path: Path\n",
    "    model_path: Path\n",
    "    metric_file_name: Path\n",
    "    target_column: str\n",
    "    params: dict[str, str]\n",
    "    grid_search_model_path: Path\n",
    "    train_data_path: Path\n",
    "    encoded_target_label: Path\n",
    "    \n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BankProducts.constants import *\n",
    "from BankProducts.utils.common  import read_yaml, create_directories\n",
    "from BankProducts   import logger\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    def get_model_evaluation_config(self) -> ModelEvaluationConfig:\n",
    "        config = self.config.model_evaluation   \n",
    "        params = self.params.random_forest\n",
    "        schema =  self.schema.target_column\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "        model_evaluation_config = ModelEvaluationConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            test_data_path=Path(config.test_data_path),\n",
    "            model_path=Path(config.model_path),\n",
    "            metric_file_name=Path(config.metric_file_name),\n",
    "            target_column=schema.name,\n",
    "            params=params,\n",
    "            grid_search_model_path= Path(config.grid_search_model_path),\n",
    "            train_data_path=Path(config.train_data_path),\n",
    "            encoded_target_label= Path(config.encoded_target_label)\n",
    "            \n",
    "            \n",
    "           \n",
    "            \n",
    "        )\n",
    "\n",
    "        return model_evaluation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e720637b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "import pandas as pd\n",
    "from BankProducts import logger\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import tempfile\n",
    "import mlflow\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from BankProducts.utils.common import save_json\n",
    "from urllib.parse import urlparse\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='_distutils_hack')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "class ModelEvaluation:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        \n",
    "         \n",
    "    \n",
    "    def eval_metrics(self, actual, pred):\n",
    "        accuracy = accuracy_score(actual, pred)\n",
    "        precision = precision_score(actual, pred, average='weighted')\n",
    "        recall = recall_score(actual, pred, average='weighted')\n",
    "        f1 = f1_score(actual, pred, average='weighted')\n",
    "        return accuracy, precision, recall, f1\n",
    "\n",
    "    def log_confusion_matrix(self, actual, predicted, class_names):\n",
    "        cm = confusion_matrix(actual, predicted)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\",\n",
    "                    xticklabels=class_names, yticklabels=class_names)\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        temp_img_path = tempfile.NamedTemporaryFile(suffix=\".png\", delete=False).name\n",
    "        plt.savefig(temp_img_path)\n",
    "        plt.close()\n",
    "        mlflow.log_artifact(temp_img_path, artifact_path=\"confusion_matrix\")\n",
    "\n",
    "    def log_classification_report(self, actual, predicted, class_names):\n",
    "        report = classification_report(actual, predicted, target_names=class_names)\n",
    "        temp_txt_path = tempfile.NamedTemporaryFile(suffix=\".txt\", delete=False).name\n",
    "        with open(temp_txt_path, \"w\") as f:\n",
    "            f.write(report)\n",
    "        mlflow.log_artifact(temp_txt_path, artifact_path=\"bank_products_recommender\")\n",
    "\n",
    "    def log_into_mlflow(self):\n",
    "        test_data = pd.read_csv(self.config.test_data_path)\n",
    "        test_x = test_data.drop(columns=[self.config.target_column])\n",
    "        \n",
    "        #  [[\"customersegment\", \"product_category\", \"amount\", \"monthlyincome\"]] \n",
    "        #test_x = test_x[['productcategory', 'amount', 'monthlyincome', 'customersegment']]\n",
    "        # print the first 5 rows of the data    \n",
    "        #print(test_x.head())\n",
    "        # Log the shape of the data\n",
    "        #logger.info(f\"Transformed data shape: {test_x.shape}\")\n",
    "        #print(f\"Transformed data shape: {X_train.shape}\")\n",
    "        \n",
    "        test_y = test_data[self.config.target_column]\n",
    "        \n",
    "\n",
    "        # Encode the target variable\n",
    "        le = joblib.load(self.config.encoded_target_label)\n",
    "        test_y_encoded = le.transform(test_y)\n",
    "\n",
    "        logger.info(\"Loading model from path: %s\", self.config.model_path)\n",
    "        pipeline = joblib.load(self.config.model_path)\n",
    "\n",
    "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "        mlflow.set_experiment(\"Product Recommender\")\n",
    "\n",
    "        if mlflow.active_run():\n",
    "            mlflow.end_run()\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            predicted = pipeline.predict(test_x)\n",
    "\n",
    "            accuracy, precision, recall, f1 = self.eval_metrics(test_y_encoded, predicted)\n",
    "            \n",
    "             # evaluate the model\n",
    "            rf_report = classification_report(test_y_encoded, predicted)\n",
    "            rf_cm = confusion_matrix(test_y_encoded, predicted)   \n",
    "            rf_accuracy = accuracy_score(test_y_encoded, predicted)   \n",
    "            \n",
    "            #create Confusion Matrix Display\n",
    "            cm_display = ConfusionMatrixDisplay(confusion_matrix=rf_cm, display_labels=le.classes_)\n",
    "                    \n",
    "            plt.title(\"RandomForestClassifier Matrix\")\n",
    "            cm_display.plot()\n",
    "            plt.xticks(rotation=180)\n",
    "            \n",
    "            \n",
    "\n",
    "            logger.info(f\"RandomForest Classification Report:\\n{rf_report}\")\n",
    "            logger.info(f\"RandomForest Confusion Matrix:\\n{rf_cm}\") \n",
    "            logger.info(f\"RandomForest Accuracy: {rf_accuracy}\")\n",
    "            \n",
    "\n",
    "            scores = {\n",
    "                \"model_name\": \"random_classifier\",\n",
    "                \"accuracy\": accuracy,\n",
    "                \"precision\": precision,\n",
    "                \"recall\": recall,\n",
    "                \"f1_score\": f1\n",
    "            }\n",
    "            \n",
    "            # Ensure directory exists\n",
    "            Path(self.config.metric_file_name).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            save_json(Path(self.config.metric_file_name), data=scores)\n",
    "            \n",
    "            logger.info(\"Metrics saved to: %s\", self.config.metric_file_name)\n",
    "            \n",
    "            logger.info(\"Logging accuracy\")\n",
    "            mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "            logger.info(\"Logging precision\")\n",
    "            mlflow.log_metric(\"precision\", precision)\n",
    "\n",
    "            logger.info(\"Logging recall\")\n",
    "            mlflow.log_metric(\"recall\", recall)\n",
    "\n",
    "            logger.info(\"Logging f1_score\")\n",
    "            mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "            logger.info(\"Setting class_names\")\n",
    "            class_names = le.classes_\n",
    "\n",
    "            logger.info(\"Logging confusion matrix\")\n",
    "            self.log_confusion_matrix(test_y_encoded, predicted, class_names)\n",
    "\n",
    "            logger.info(\"Logging classification report\")\n",
    "            self.log_classification_report(test_y_encoded, predicted, class_names)\n",
    "            \n",
    "            \n",
    "            logger.info(\"Tracking URI scheme: %s\", tracking_url_type_store)\n",
    "            logger.info(\"Tracking URI: %s\", mlflow.get_tracking_uri())\n",
    "\n",
    "\n",
    "            #if tracking_url_type_store != \"file\":\n",
    "                #mlflow.sklearn.log_model(pipeline, \"pipeline\", registered_model_name=\"product recommender\")\n",
    "            #else:\n",
    "                #mlflow.sklearn.log_model(pipeline, \"pipeline\")\n",
    "              \n",
    "            logger.info(\"mlflow model logged successfully.\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "    # perform a Grid Search to find the best model\n",
    "    def perform_grid_search(self):\n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "        from sklearn.pipeline import Pipeline\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "        from sklearn.compose import ColumnTransformer\n",
    "\n",
    "        # Load **training** data for grid search\n",
    "        train_data = pd.read_csv(self.config.test_data_path)\n",
    "        X_train = train_data.drop(columns=[self.config.target_column])\n",
    "        y_train = train_data[self.config.target_column]\n",
    "\n",
    "        # Define preprocessing steps\n",
    "        numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "        categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', StandardScaler(), numeric_features),\n",
    "                ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "            ])\n",
    "\n",
    "        # Define the model\n",
    "        model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "        # Create a pipeline\n",
    "        pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
    "\n",
    "        # Define hyperparameter grid\n",
    "        param_grid = {\n",
    "            'classifier__n_estimators': [50, 100, 200],\n",
    "            'classifier__max_depth': [None, 10, 20],\n",
    "            'classifier__min_samples_split': [2, 5, 10],\n",
    "            'classifier__max_features': ['sqrt', 'log2'], \n",
    "            'classifier__min_samples_leaf': [1, 2, 4],\n",
    "            'classifier__class_weight': ['balanced', None],\n",
    "            'classifier__n_jobs': [-1]\n",
    "        }\n",
    "\n",
    "        # Perform grid search with cross-validation\n",
    "        grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        logger.info(\"Best parameters found: %s\", grid_search.best_params_)\n",
    "\n",
    "        # Save the best model\n",
    "        joblib.dump(grid_search.best_estimator_, self.config.grid_search_model_path)\n",
    "        logger.info(\"Best model saved to: %s\", self.config.grid_search_model_path)\n",
    "\n",
    "        #  Feature importance works only with numeric column names (after encoding)\n",
    "        # This part needs to be handled carefully after transformation\n",
    "        try:\n",
    "            classifier = grid_search.best_estimator_.named_steps['classifier']\n",
    "            importances = classifier.feature_importances_\n",
    "\n",
    "            # Just return dummy placeholder since true mapping is complicated\n",
    "            importance_df = pd.DataFrame({'importance': importances})\n",
    "        except Exception as e:\n",
    "            logger.warning(\"Could not extract feature importances: %s\", e)\n",
    "            importance_df = pd.DataFrame()\n",
    "\n",
    "        return importance_df\n",
    "\n",
    "                                                                        \n",
    "    \n",
    "    \n",
    "    # perform validation using cross validation\n",
    "    def validate_model(self):\n",
    "        test_data = pd.read_csv(self.config.test_data_path)\n",
    "        test_x = test_data.drop(columns=[self.config.target_column])\n",
    "        test_y = test_data[self.config.target_column]\n",
    "        \n",
    "        print(test_x.head())\n",
    "        print(test_y.head())\n",
    "        logger.info(\"Starting model validation...\")\n",
    "\n",
    "        # Load pipeline and label encoder\n",
    "        pipeline = joblib.load(self.config.model_path)\n",
    "        label_encoder = joblib.load(self.config.encoded_target_label)\n",
    "\n",
    "        # Encode test_y using the same encoder used during training\n",
    "        test_y_encoded = label_encoder.transform(test_y)\n",
    "\n",
    "        # Perform cross-validation on test data\n",
    "        from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "        cv = StratifiedKFold(n_splits=5)\n",
    "        scores = cross_val_score(pipeline, test_x, test_y_encoded, cv=cv, scoring='accuracy')\n",
    "\n",
    "        logger.info(\"Cross-validation scores: %s\", scores)\n",
    "        logger.info(\"Mean cross-validation score: %.2f\", scores.mean())\n",
    "\n",
    "        return scores.mean()\n",
    "\n",
    "\n",
    "            \n",
    "    \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-09 21:32:23,956: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-06-09 21:32:23,982: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-06-09 21:32:24,039: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2025-06-09 21:32:24,044: INFO: common: created directory at: artifacts]\n",
      "[2025-06-09 21:32:24,048: INFO: common: created directory at: artifacts]\n",
      "[2025-06-09 21:32:24,201: INFO: 1552210882: Loading model from path: artifacts\\model_training\\random.joblib]\n",
      "[2025-06-09 21:32:27,612: INFO: 1552210882: RandomForest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       800\n",
      "           1       0.99      0.98      0.98      1071\n",
      "           2       0.97      1.00      0.99       552\n",
      "           3       1.00      0.96      0.98      1530\n",
      "           4       0.89      1.00      0.94       270\n",
      "           5       0.95      1.00      0.98       544\n",
      "           6       1.00      0.99      0.99      1233\n",
      "\n",
      "    accuracy                           0.98      6000\n",
      "   macro avg       0.97      0.99      0.98      6000\n",
      "weighted avg       0.98      0.98      0.98      6000\n",
      "]\n",
      "[2025-06-09 21:32:27,617: INFO: 1552210882: RandomForest Confusion Matrix:\n",
      "[[ 795    0    5    0    0    0    0]\n",
      " [   0 1045   11    1    0   14    0]\n",
      " [   0    0  552    0    0    0    0]\n",
      " [   9   10    0 1472   33    0    6]\n",
      " [   0    0    0    0  270    0    0]\n",
      " [   0    0    0    0    0  544    0]\n",
      " [   0    0    0    5    0   12 1216]]]\n",
      "[2025-06-09 21:32:27,620: INFO: 1552210882: RandomForest Accuracy: 0.9823333333333333]\n",
      "[2025-06-09 21:32:27,625: INFO: common: json file saved at: artifacts\\model_evaluation\\metrics.json]\n",
      "[2025-06-09 21:32:27,628: INFO: 1552210882: Metrics saved to: artifacts\\model_evaluation\\metrics.json]\n",
      "[2025-06-09 21:32:27,631: INFO: 1552210882: Logging accuracy]\n",
      "[2025-06-09 21:32:27,647: INFO: 1552210882: Logging precision]\n",
      "[2025-06-09 21:32:27,678: INFO: 1552210882: Logging recall]\n",
      "[2025-06-09 21:32:27,691: INFO: 1552210882: Logging f1_score]\n",
      "[2025-06-09 21:32:27,711: INFO: 1552210882: Setting class_names]\n",
      "[2025-06-09 21:32:27,716: INFO: 1552210882: Logging confusion matrix]\n",
      "[2025-06-09 21:32:29,596: INFO: 1552210882: Logging classification report]\n",
      "[2025-06-09 21:32:30,478: INFO: 1552210882: Tracking URI scheme: file]\n",
      "[2025-06-09 21:32:30,482: INFO: 1552210882: Tracking URI: file:///C:/Users/RICH-FILES/Desktop/ml/AI-powered-Bank-Product-Recommender-Chatbot/mlruns]\n",
      "[2025-06-09 21:32:30,484: INFO: 1552210882: mlflow model logged successfully.]\n",
      "  transactiontype       amount   productcategory productsubcategory  \\\n",
      "0             Fee  6234.909003       Credit Card           Standard   \n",
      "1    Loan Payment  3352.094565              Loan           Platinum   \n",
      "2      Withdrawal  2665.193446  Checking Account               Gold   \n",
      "3      Withdrawal  8321.374295       Credit Card               Gold   \n",
      "4    Loan Payment  7530.153337              Loan           Standard   \n",
      "\n",
      "   customerscore  monthlyincome  channel_count_atm  channel_count_branch  \\\n",
      "0            441        7264.58                  1                     4   \n",
      "1            447        3432.04                  0                     1   \n",
      "2            418        4183.91                  1                     0   \n",
      "3            661        1870.79                  1                     2   \n",
      "4            803        9070.85                  0                     0   \n",
      "\n",
      "   channel_count_mobile  channel_count_online most_used_channel  year  month  \\\n",
      "0                     0                     0            Branch  2023      7   \n",
      "1                     1                     1            Branch  2023      4   \n",
      "2                     2                     0            Mobile  2024      2   \n",
      "3                     0                     1            Branch  2023     10   \n",
      "4                     2                     1            Mobile  2025      2   \n",
      "\n",
      "   day  is_branch  is_atm  is_mobile  is_online  \n",
      "0   19          1       0          0          0  \n",
      "1   15          1       0          0          0  \n",
      "2    4          0       0          1          0  \n",
      "3   24          0       0          0          1  \n",
      "4    5          0       0          1          0  \n",
      "0           Exclusive Platinum Package\n",
      "1         Personal Loan Cashback Offer\n",
      "2             Mid-tier Savings Booster\n",
      "3    Financial Literacy Program Access\n",
      "4          Premium Investment Services\n",
      "Name: recommendedoffer, dtype: object\n",
      "[2025-06-09 21:32:30,670: INFO: 1552210882: Starting model validation...]\n",
      "[2025-06-09 21:32:52,289: INFO: 1552210882: Cross-validation scores: [0.97583333 0.96333333 0.96916667 0.96833333 0.97583333]]\n",
      "[2025-06-09 21:32:52,293: INFO: 1552210882: Mean cross-validation score: 0.97]\n",
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_evaluation_config = config.get_model_evaluation_config()\n",
    "    eval = ModelEvaluation(config=model_evaluation_config)\n",
    "    eval.log_into_mlflow()\n",
    "    eval.validate_model()\n",
    "    eval.perform_grid_search()  \n",
    "    \n",
    "    \n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9469ccb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6710aab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19386016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaa7a66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea8dca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55592b65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc40b527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06341f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bankprod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
