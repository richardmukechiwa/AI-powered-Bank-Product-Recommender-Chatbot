{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fd282c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ded44414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\RICH-FILES\\\\Desktop\\\\ml\\\\AI-powered-Bank-Product-Recommender-Chatbot'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "630722c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5199b4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\RICH-FILES\\\\Desktop\\\\ml'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2dc57d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = \"C:/Users/RICH-FILES/Desktop/ml/AI-powered-Bank-Product-Recommender-Chatbot\"\n",
    "os.chdir(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36c167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainingConfig:\n",
    "    \"\"\"Configuration for model training.\n",
    "    \"\"\"\n",
    "    model_name: str\n",
    "    root_dir: Path\n",
    "    test_data_dir: Path\n",
    "    train_data_dir: Path\n",
    "    #criterion: str\n",
    "    #max_features: int\n",
    "    #min_samples_split: int\n",
    "    #min_samples_leaf: int\n",
    "    n_estimators: int\n",
    "    #max_depth: int\n",
    "    random_state: int\n",
    "    #class_weight: str\n",
    "    #n_jobs: int\n",
    "    target_column: str\n",
    "    booster: str\n",
    "    \n",
    "    objective: str\n",
    "    num_class: int\n",
    "    n_estimators: int\n",
    "    learning_rate: float\n",
    "    max_depth: int\n",
    "    subsample: float        \n",
    "    colsample_bytree: float\n",
    "    random_state: int   \n",
    "    \n",
    "    \n",
    "    random_state: int\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1f5169ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BankProducts.constants import *\n",
    "from BankProducts.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec671740",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    def get_model_training_config(self) -> ModelTrainingConfig:\n",
    "        config = self.config.model_training\n",
    "        params = self.params.xgb_classifier\n",
    "        schema =  self.schema.target_column\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "        model_training_config = ModelTrainingConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            train_data_dir = Path(config.train_data_dir),\n",
    "            test_data_dir = Path(config.test_data_dir),\n",
    "            model_name = config.model_name,\n",
    "            #criterion = params.criterion,\n",
    "            #max_features = params.max_features,\n",
    "            #min_samples_split = params.min_samples_split,\n",
    "            #min_samples_leaf = params.min_samples_leaf,\n",
    "            n_estimators = params.n_estimators, \n",
    "            #max_depth = params.max_depth,\n",
    "            random_state = params.random_state,\n",
    "            #class_weight = params.class_weight,\n",
    "            #n_jobs = params.n_jobs,\n",
    "            target_column = schema.name,\n",
    "            objective = params.objective,\n",
    "            num_class = params.num_class,\n",
    "            learning_rate = params.learning_rate,\n",
    "            subsample = params.subsample,\n",
    "            colsample_bytree = params.colsample_bytree,\n",
    "            max_depth = params.max_depth,\n",
    "            booster = params.booster\n",
    "                           \n",
    "            \n",
    "        )\n",
    "\n",
    "        return model_training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "77d8ed93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from BankProducts import logger\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99a4436",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTraining:\n",
    "    def __init__(self, config: ModelTrainingConfig):\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "\n",
    "    def train(self):\n",
    "        logger.info(\"Loading training data\")\n",
    "        train_data = pd.read_csv(self.config.train_data_dir)\n",
    "        X_train = train_data.drop(columns=[self.config.target_column])\n",
    "        y_train = train_data[self.config.target_column]\n",
    "        \n",
    "        # encode the target variable if it's categorical\n",
    "        if y_train.dtype == 'object' or y_train.dtype.name == 'category':\n",
    "            logger.info(\"Encoding target variable\")\n",
    "            label_encoder = LabelEncoder()\n",
    "            y_train = label_encoder.fit_transform(y_train)\n",
    "        else:\n",
    "            logger.info(\"Target variable is already numeric, no encoding needed\")   \n",
    "        logger.info(\"Loading validation data\")\n",
    "        \n",
    "        \n",
    "        logger.info(\"Training the model\")\n",
    "        # Identify categorical and numerical features\n",
    "        categorical_features = X_train.select_dtypes(exclude='number').columns.tolist()\n",
    "        numerical_features = X_train.select_dtypes(include=['number']).columns.tolist()\n",
    "      \n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features),\n",
    "                ('num', SimpleImputer(strategy='mean'), numerical_features)\n",
    "            ],\n",
    "            remainder='passthrough'  # Keep other columns as they are\n",
    "        )\n",
    "\n",
    "        # Initialize the RandomForestClassifier with the provided configuration\n",
    "        model = XGBClassifier(\n",
    "            objective=self.config.objective,\n",
    "            booster=self.config.booster,\n",
    "            num_class=self.config.num_class,\n",
    "            n_estimators=self.config.n_estimators,\n",
    "            learning_rate=self.config.learning_rate,\n",
    "            max_depth=self.config.max_depth,\n",
    "            subsample=self.config.subsample,\n",
    "            colsample_bytree=self.config.colsample_bytree,\n",
    "            random_state=self.config.random_state\n",
    "        )\n",
    "        \n",
    "\n",
    "        # Create the pipeline combining preprocessing, scaling, and modeling\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features),\n",
    "                ('num', Pipeline([\n",
    "                    ('imputer', SimpleImputer(strategy='mean')),\n",
    "                    ('scaler', StandardScaler())\n",
    "                ]), numerical_features)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "\n",
    "        # Fit the pipeline to the training data\n",
    "        \n",
    "        \n",
    "        print(\"X_TRAIN\", X_train[:15])\n",
    "        print(\"Y_train\", y_train[:10])\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        import numpy as np\n",
    "\n",
    "        classifier = pipeline.named_steps['classifier']\n",
    "        preprocessor = pipeline.named_steps['preprocessor']\n",
    "\n",
    "        # Get feature names after preprocessing\n",
    "        feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "        # Get importances\n",
    "        importances = classifier.feature_importances_\n",
    "        sorted_indices = np.argsort(importances)[::-1]\n",
    "\n",
    "        print(\"Top 20 important features:\")\n",
    "        for i in sorted_indices[:20]:\n",
    "            print(f\"{feature_names[i]}: {importances[i]:.4f}\")\n",
    "\n",
    "\n",
    "        logger.info(\"Saving the trained model\")\n",
    "        \n",
    "                \n",
    "        # Create directory if it doesn't exist\n",
    "        model_dir = self.config.root_dir\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        \n",
    "        print(\"Model directory:\", model_dir)\n",
    "        print(\"Directory exists?\", os.path.exists(model_dir))\n",
    "        print(\"Is a directory?\", os.path.isdir(model_dir))\n",
    "\n",
    "                \n",
    "        model_path = os.path.join(model_dir, self.config.model_name)\n",
    "        \n",
    "        print(\"Model path:\", model_path)\n",
    "        # Ensure the model path is a Path object\n",
    "        model_path = Path(model_path)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        print(\"Model will be saved to:\", model_path)\n",
    "        \n",
    "                # Safety check: if a directory exists where the model file should go, delete it\n",
    "        if os.path.isdir(model_path):\n",
    "            import shutil\n",
    "            logger.warning(f\"A folder exists at model path '{model_path}', deleting it.\")\n",
    "            shutil.rmtree(model_path)\n",
    "            \n",
    "        # Save the model to the specified path\n",
    "        self.model = pipeline \n",
    "\n",
    "   \n",
    "        # Save the model using joblib\n",
    "        joblib.dump(self.model, model_path, compress=4)\n",
    "      \n",
    "        \n",
    "        logger.info(\"Model training completed successfully\")\n",
    "        \n",
    "        import seaborn as sns\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        for feature in ['annual_income', 'credit_score', 'age']:\n",
    "            plt.figure(figsize=(8,4))\n",
    "            sns.boxplot(x='product_name', y=feature, data=train_data)\n",
    "            plt.title(f'{feature} by Product')\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "83d5cd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-31 22:37:33,793: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-05-31 22:37:33,825: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-05-31 22:37:33,839: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2025-05-31 22:37:33,843: INFO: common: created directory at: artifacts]\n",
      "[2025-05-31 22:37:33,848: INFO: common: created directory at: artifacts]\n",
      "[2025-05-31 22:37:33,851: ERROR: 4071221513: An error occurred during model training: ModelTrainingConfig.__init__() missing 1 required positional argument: 'max_depth']\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\RICH-FILES\\AppData\\Local\\Temp\\ipykernel_11524\\4071221513.py\", line 3, in <module>\n",
      "    model_training_config = config.get_model_training_config()\n",
      "  File \"C:\\Users\\RICH-FILES\\AppData\\Local\\Temp\\ipykernel_11524\\3543156192.py\", line 22, in get_model_training_config\n",
      "    model_training_config = ModelTrainingConfig(\n",
      "TypeError: ModelTrainingConfig.__init__() missing 1 required positional argument: 'max_depth'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_training_config = config.get_model_training_config()\n",
    "    model_trainer = ModelTraining(config=model_training_config)\n",
    "    model_trainer.train()\n",
    "except Exception as e:\n",
    "    logger.exception(f\"An error occurred during model training: {e}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bankprod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
