{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fd282c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ded44414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\RICH-FILES\\\\Desktop\\\\ml\\\\AI-powered-Bank-Product-Recommender-Chatbot'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "630722c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5199b4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\RICH-FILES\\\\Desktop\\\\ml'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2dc57d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = \"C:/Users/RICH-FILES/Desktop/ml/AI-powered-Bank-Product-Recommender-Chatbot\"\n",
    "os.chdir(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f36c167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainingConfig:\n",
    "    \"\"\"Configuration for model training.\n",
    "    \"\"\"\n",
    "    model_name: str\n",
    "    root_dir: Path\n",
    "    test_data_dir: Path\n",
    "    train_data_dir: Path\n",
    "    criterion: str\n",
    "    max_features: int\n",
    "    min_samples_split: int\n",
    "    min_samples_leaf: int\n",
    "    n_estimators: int\n",
    "    max_depth: int\n",
    "    random_state: int\n",
    "    class_weight: str\n",
    "    n_jobs: int\n",
    "    target_column: str\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1f5169ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BankProducts.constants import *\n",
    "from BankProducts.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ec671740",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    def get_model_training_config(self) -> ModelTrainingConfig:\n",
    "        config = self.config.model_training\n",
    "        params = self.params.random_forest\n",
    "        schema =  self.schema.target_column\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "        model_training_config = ModelTrainingConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            train_data_dir = Path(config.train_data_dir),\n",
    "            test_data_dir = Path(config.test_data_dir),\n",
    "            model_name = config.model_name,\n",
    "            criterion = params.criterion,\n",
    "            max_features = params.max_features,\n",
    "            min_samples_split = params.min_samples_split,\n",
    "            min_samples_leaf = params.min_samples_leaf,\n",
    "            n_estimators = params.n_estimators, \n",
    "            max_depth = params.max_depth,\n",
    "            random_state = params.random_state,\n",
    "            class_weight = params.class_weight,\n",
    "            n_jobs = params.n_jobs,\n",
    "            target_column = schema.name\n",
    "            \n",
    "        )\n",
    "\n",
    "        return model_training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "77d8ed93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from BankProducts import logger\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99a4436",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTraining:\n",
    "    def __init__(self, config: ModelTrainingConfig):\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "\n",
    "    def train(self):\n",
    "        logger.info(\"Loading training data\")\n",
    "        train_data = pd.read_csv(self.config.train_data_dir)\n",
    "        X_train = train_data.drop(columns=[self.config.target_column])\n",
    "        y_train = train_data[self.config.target_column]\n",
    "        \n",
    "        # encode the target variable if it's categorical\n",
    "        if y_train.dtype == 'object' or y_train.dtype.name == 'category':\n",
    "            logger.info(\"Encoding target variable\")\n",
    "            label_encoder = LabelEncoder()\n",
    "            y_train = label_encoder.fit_transform(y_train)\n",
    "        else:\n",
    "            logger.info(\"Target variable is already numeric, no encoding needed\")   \n",
    "        logger.info(\"Loading validation data\")\n",
    "        \n",
    "        \n",
    "        logger.info(\"Training the model\")\n",
    "        # Identify categorical and numerical features\n",
    "        categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        numerical_features = X_train.select_dtypes(include=['number']).columns.tolist()\n",
    "      \n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features),\n",
    "                ('num', SimpleImputer(strategy='mean'), numerical_features)\n",
    "            ],\n",
    "            remainder='passthrough'  # Keep other columns as they are\n",
    "        )\n",
    "\n",
    "        # Initialize the RandomForestClassifier with the provided configuration\n",
    "        model = RandomForestClassifier(\n",
    "            criterion=self.config.criterion,\n",
    "            max_features=self.config.max_features,\n",
    "            min_samples_split=self.config.min_samples_split,\n",
    "            min_samples_leaf=self.config.min_samples_leaf,\n",
    "            n_estimators=self.config.n_estimators,  \n",
    "            max_depth=self.config.max_depth,\n",
    "            random_state=self.config.random_state,\n",
    "            class_weight=self.config.class_weight,\n",
    "            n_jobs=self.config.n_jobs\n",
    "        )\n",
    "\n",
    "        # Create the pipeline combining preprocessing, scaling, and modeling\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('scaler', StandardScaler()),   # Optional: Only applies to numerical after preprocessing\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "        \n",
    "        # Fit the pipeline to the training data\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        logger.info(\"Saving the trained model\")\n",
    "        \n",
    "                \n",
    "        # Create directory if it doesn't exist\n",
    "        model_dir = self.config.root_dir\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        \n",
    "        print(\"Model directory:\", model_dir)\n",
    "        print(\"Directory exists?\", os.path.exists(model_dir))\n",
    "        print(\"Is a directory?\", os.path.isdir(model_dir))\n",
    "\n",
    "                \n",
    "        model_path = os.path.join(model_dir, self.config.model_name)\n",
    "        \n",
    "        print(\"Model path:\", model_path)\n",
    "        # Ensure the model path is a Path object\n",
    "        model_path = Path(model_path)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        print(\"Model will be saved to:\", model_path)\n",
    "        \n",
    "                # Safety check: if a directory exists where the model file should go, delete it\n",
    "        if os.path.isdir(model_path):\n",
    "            import shutil\n",
    "            logger.warning(f\"A folder exists at model path '{model_path}', deleting it.\")\n",
    "            shutil.rmtree(model_path)\n",
    "\n",
    "\n",
    "   \n",
    "        # Save the model using joblib\n",
    "        joblib.dump(self.model, model_path, compress=4)\n",
    "      \n",
    "        \n",
    "        logger.info(\"Model training completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "83d5cd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-24 22:43:19,053: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-05-24 22:43:19,062: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-05-24 22:43:19,073: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2025-05-24 22:43:19,078: INFO: common: created directory at: artifacts]\n",
      "[2025-05-24 22:43:19,082: INFO: common: created directory at: artifacts]\n",
      "[2025-05-24 22:43:19,086: INFO: 2501898837: Loading training data]\n",
      "[2025-05-24 22:43:19,196: INFO: 2501898837: Encoding target variable]\n",
      "[2025-05-24 22:43:19,203: INFO: 2501898837: Loading validation data]\n",
      "[2025-05-24 22:43:19,206: INFO: 2501898837: Training the model]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-24 22:43:22,236: INFO: 2501898837: Saving the trained model]\n",
      "Model directory: artifacts\\model_training\n",
      "Directory exists? True\n",
      "Is a directory? True\n",
      "Model path: artifacts\\model_training\\model.joblib\n",
      "Model will be saved to: artifacts\\model_training\\model.joblib\n",
      "[2025-05-24 22:43:22,244: ERROR: 4071221513: An error occurred during model training: [Errno 13] Permission denied: 'artifacts\\\\model_training\\\\model.joblib']\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\RICH-FILES\\AppData\\Local\\Temp\\ipykernel_7968\\4071221513.py\", line 5, in <module>\n",
      "    model_trainer.train()\n",
      "  File \"C:\\Users\\RICH-FILES\\AppData\\Local\\Temp\\ipykernel_7968\\2501898837.py\", line 85, in train\n",
      "    joblib.dump(self.model, model_path, compress=4)\n",
      "  File \"c:\\Users\\RICH-FILES\\anacoda4\\envs\\bankprod\\lib\\site-packages\\joblib\\numpy_pickle.py\", line 594, in dump\n",
      "    with _write_fileobject(\n",
      "  File \"c:\\Users\\RICH-FILES\\anacoda4\\envs\\bankprod\\lib\\site-packages\\joblib\\numpy_pickle_utils.py\", line 222, in _write_fileobject\n",
      "    file_instance = _COMPRESSORS[\"zlib\"].compressor_file(\n",
      "  File \"c:\\Users\\RICH-FILES\\anacoda4\\envs\\bankprod\\lib\\site-packages\\joblib\\compressor.py\", line 114, in compressor_file\n",
      "    return self.fileobj_factory(fileobj, \"wb\", compresslevel=compresslevel)\n",
      "  File \"c:\\Users\\RICH-FILES\\anacoda4\\envs\\bankprod\\lib\\site-packages\\joblib\\compressor.py\", line 289, in __init__\n",
      "    self._fp = io.open(filename, mode)\n",
      "PermissionError: [Errno 13] Permission denied: 'artifacts\\\\model_training\\\\model.joblib'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_training_config = config.get_model_training_config()\n",
    "    model_trainer = ModelTraining(config=model_training_config)\n",
    "    model_trainer.train()\n",
    "except Exception as e:\n",
    "    logger.exception(f\"An error occurred during model training: {e}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bankprod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
