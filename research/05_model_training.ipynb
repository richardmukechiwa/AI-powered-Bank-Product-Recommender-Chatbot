{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "fd282c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "ded44414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\RICH-FILES\\\\Desktop\\\\ml\\\\AI-powered-Bank-Product-Recommender-Chatbot'"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "630722c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "5199b4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\RICH-FILES\\\\Desktop\\\\ml'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "2dc57d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = \"C:/Users/RICH-FILES/Desktop/ml/AI-powered-Bank-Product-Recommender-Chatbot\"\n",
    "os.chdir(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "f36c167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainingConfig:\n",
    "    \"\"\"Configuration for model training.\n",
    "    \"\"\"\n",
    "    model_name: str\n",
    "    root_dir: Path\n",
    "    test_data_dir: Path\n",
    "    train_data_dir: Path\n",
    "    #criterion: str\n",
    "    #max_features: int\n",
    "    #min_samples_split: int\n",
    "    #min_samples_leaf: int\n",
    "    #n_estimators: int\n",
    "    #max_depth: int\n",
    "    random_state: int\n",
    "    class_weight: str\n",
    "    n_jobs: int\n",
    "    target_column: str\n",
    "    label_encoder_file: str\n",
    "    C: float\n",
    "    penalty: str\n",
    "    solver: str\n",
    "    max_iter: int\n",
    "    \n",
    "   \n",
    "    \n",
    "   \n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "1f5169ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BankProducts.constants import *\n",
    "from BankProducts.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "ec671740",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    def get_model_training_config(self) -> ModelTrainingConfig:\n",
    "        config = self.config.model_training\n",
    "        params = self.params.logistic_regression\n",
    "        schema =  self.schema.target_column\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "        model_training_config = ModelTrainingConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            train_data_dir = Path(config.train_data_dir),\n",
    "            test_data_dir = Path(config.test_data_dir),\n",
    "            model_name = config.model_name,\n",
    "            #criterion = params.criterion,\n",
    "            #max_features = params.max_features,\n",
    "            #min_samples_split = params.min_samples_split,\n",
    "            #min_samples_leaf = params.min_samples_leaf,\n",
    "            #n_estimators = params.n_estimators, \n",
    "            #max_depth = params.max_depth,\n",
    "            random_state = params.random_state,\n",
    "            class_weight = params.class_weight,\n",
    "            n_jobs = params.n_jobs,\n",
    "            target_column = schema.name,\n",
    "            label_encoder_file = config.label_encoder_file,\n",
    "            C = params.C,\n",
    "            penalty = params.penalty,\n",
    "            solver = params.solver, \n",
    "            max_iter = params.max_iter\n",
    "            )\n",
    "           \n",
    "            \n",
    "        \n",
    "\n",
    "        return model_training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "77d8ed93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from BankProducts import logger\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99a4436",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTraining:\n",
    "    def __init__(self, config: ModelTrainingConfig):\n",
    "        self.config = config\n",
    "        self.model = None\n",
    "\n",
    "    def train(self):\n",
    "        logger.info(\"Loading training data\")\n",
    "        \n",
    "        os.makedirs(os.path.dirname(self.config.train_data_dir), exist_ok=True)\n",
    "        # Load the training data\n",
    "        \n",
    "        train_data = pd.read_csv(self.config.train_data_dir)\n",
    "        X_train = train_data.drop(columns=[self.config.target_column])\n",
    "        #  [[\"customersegment\", \"product_category\", \"amount\", \"monthlyincome\"]] \n",
    "        #X_train = X_train[['productcategory', 'amount', 'monthlyincome', 'customersegment']]\n",
    "        # print the first 5 rows of the data    \n",
    "        #print(X_train.head())\n",
    "        # Log the shape of the data\n",
    "        #logger.info(f\"Transformed data shape: {X_train.shape}\")\n",
    "        #print(f\"Transformed data shape: {X_train.shape}\")\n",
    "        \n",
    "        y_train = train_data[self.config.target_column]\n",
    "        \n",
    "        # encode the target variable if it's categorical\n",
    "        if y_train.dtype == 'object' or y_train.dtype.name == 'category':\n",
    "            logger.info(\"Encoding target variable\")\n",
    "            label_encoder = LabelEncoder()\n",
    "            y_train = label_encoder.fit_transform(y_train)\n",
    "        else:\n",
    "            logger.info(\"Target variable is already numeric, no encoding needed\")   \n",
    "        logger.info(\"Loading validation data\")\n",
    "        \n",
    "         # Create directory if it doesn't exist\n",
    "        model_dir = self.config.root_dir\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        \n",
    "       \n",
    "        \n",
    "        # save the label_encoder for future use\n",
    "        label_encoder_path = os.path.join(model_dir , self.config.label_encoder_file)\n",
    "        joblib.dump(label_encoder, label_encoder_path)\n",
    "        \n",
    "        logger.info(\"Label encoder saved to: %s\", label_encoder_path)\n",
    "         \n",
    "        \n",
    "        logger.info(\"Training the model\")\n",
    "        # Identify categorical and numerical features\n",
    "        categorical_features = X_train.select_dtypes(exclude='number').columns.tolist()\n",
    "        numerical_features = X_train.select_dtypes(include=['number']).columns.tolist()\n",
    "      \n",
    "        #preprocessor = ColumnTransformer(\n",
    "            #transformers=[\n",
    "                #('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features),\n",
    "                #('num', SimpleImputer(strategy='mean'), numerical_features)\n",
    "            #],\n",
    "           # remainder='passthrough'  # Keep other columns as they are\n",
    "        #)\n",
    "\n",
    "        # Initialize the RandomForestClassifier with the provided configuration\n",
    "        model = LogisticRegression(\n",
    "            C=self.config.C,\n",
    "            penalty=self.config.penalty,\n",
    "            solver=self.config.solver,\n",
    "            max_iter=self.config.max_iter,\n",
    "            random_state=self.config.random_state,      \n",
    "            class_weight=self.config.class_weight,      \n",
    "            n_jobs=self.config.n_jobs\n",
    "        )\n",
    "        #model = RandomForestClassifier(\n",
    "        \n",
    "        \n",
    "       # Create the pipeline combining preprocessing, scaling, and modeling\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features),\n",
    "                ('num', Pipeline([\n",
    "                    ('imputer', SimpleImputer(strategy='mean')),\n",
    "                    ('scaler', StandardScaler())\n",
    "                ]), numerical_features)\n",
    "            ],\n",
    "            remainder='passthrough' \n",
    "        )\n",
    "\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "\n",
    "        # Fit the pipeline to the training data\n",
    "        \n",
    "        \n",
    "        print(\"X_TRAIN\", X_train[:15])\n",
    "        print(\"Y_train\", y_train[:10])\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        X_train_transformed = pipeline.named_steps['preprocessor'].transform(X_train)\n",
    "        print(\"X_train after preprocessing:\", X_train_transformed[:1])\n",
    "\n",
    "        \n",
    "        import numpy as np\n",
    "\n",
    "        classifier = pipeline.named_steps['classifier']\n",
    "        preprocessor = pipeline.named_steps['preprocessor']\n",
    "\n",
    "        # Get feature names after preprocessing\n",
    "        feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "        # Get the coefficient matrix (shape: n_classes x n_features)\n",
    "        coefs = classifier.coef_\n",
    "\n",
    "        # Take the mean of absolute values across all classes (axis=0)\n",
    "        importances = np.mean(np.abs(coefs), axis=0)\n",
    "        \n",
    "        # Sort by importance\n",
    "        sorted_indices = np.argsort(importances)[::-1]\n",
    "\n",
    "        # Limit to top N (avoid index errors)\n",
    "        top_n = min(20, len(sorted_indices))\n",
    "\n",
    "        # Display\n",
    "        print(\"Top important features (averaged across all classes):\")\n",
    "        for i in sorted_indices[:top_n]:\n",
    "            \n",
    "            \n",
    "            print(f\"{feature_names[i]}: {importances[i]:.4f}\")\n",
    "\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        top_features = [feature_names[i] for i in sorted_indices[:top_n]]\n",
    "        top_importance_values = [importances[i] for i in sorted_indices[:top_n]]\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.barh(top_features[::-1], top_importance_values[::-1])\n",
    "        plt.title(\"Top Features (Avg Absolute Coefficients - Multiclass Logistic Regression)\")\n",
    "        plt.xlabel(\"Average Absolute Coefficient\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        classes = classifier.classes_  # e.g., array([0, 1, 2])\n",
    "\n",
    "        for class_index, class_label in enumerate(classes):\n",
    "            print(f\"\\nTop features for class {class_label}:\")\n",
    "            class_coefs = coefs[class_index]\n",
    "            sorted_idx = np.argsort(np.abs(class_coefs))[::-1]\n",
    "            \n",
    "            for i in sorted_idx[:10]:\n",
    "                print(f\"{feature_names[i]}: {class_coefs[i]:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "            \n",
    "            import matplotlib.pyplot as plt\n",
    "\n",
    "            top_features = [feature_names[i] for i in sorted_indices[:top_n]]\n",
    "            top_importances = [importances[i] for i in sorted_indices[:top_n]]\n",
    "\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.barh(top_features[::-1], top_importances[::-1])\n",
    "            plt.title(\"Top Important Features (Logistic Regression Coefficients)\")\n",
    "            plt.xlabel(\"Coefficient Value\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "        logger.info(\"Saving the trained model\")\n",
    "        \n",
    "                \n",
    "        # Create directory if it doesn't exist\n",
    "        model_dir = self.config.root_dir\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        \n",
    "        print(\"Model directory:\", model_dir)\n",
    "        print(\"Directory exists?\", os.path.exists(model_dir))\n",
    "        print(\"Is a directory?\", os.path.isdir(model_dir))\n",
    "\n",
    "                \n",
    "        model_path = os.path.join(model_dir, self.config.model_name)\n",
    "        \n",
    "        print(\"Model path:\", model_path)\n",
    "        # Ensure the model path is a Path object\n",
    "        model_path = Path(model_path)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        print(\"Model will be saved to:\", model_path)\n",
    "        \n",
    "                # Safety check: if a directory exists where the model file should go, delete it\n",
    "        if os.path.isdir(model_path):\n",
    "            import shutil\n",
    "            logger.warning(f\"A folder exists at model path '{model_path}', deleting it.\")\n",
    "            shutil.rmtree(model_path)\n",
    "            \n",
    "        # Save the model to the specified path\n",
    "        self.model = pipeline \n",
    "\n",
    "   \n",
    "        # Save the model using joblib\n",
    "        joblib.dump(self.model, model_path, compress=4)\n",
    "      \n",
    "        \n",
    "        logger.info(\"Model training completed successfully\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "83d5cd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-09 21:24:54,299: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-06-09 21:24:54,317: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-06-09 21:24:54,333: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2025-06-09 21:24:54,338: INFO: common: created directory at: artifacts]\n",
      "[2025-06-09 21:24:54,342: INFO: common: created directory at: artifacts]\n",
      "[2025-06-09 21:24:54,344: INFO: 4034810082: Loading training data]\n",
      "[2025-06-09 21:24:54,494: INFO: 4034810082: Encoding target variable]\n",
      "[2025-06-09 21:24:54,546: INFO: 4034810082: Loading validation data]\n",
      "[2025-06-09 21:24:54,554: INFO: 4034810082: Label encoder saved to: artifacts\\model_training\\label_encoder.joblib]\n",
      "[2025-06-09 21:24:54,557: INFO: 4034810082: Training the model]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_TRAIN    transactiontype        amount  ... is_mobile is_online\n",
      "0          Deposit  12075.266419  ...         0         0\n",
      "1       Withdrawal   7972.298175  ...         0         0\n",
      "2     Card Payment   3821.334547  ...         0         0\n",
      "3       Withdrawal    945.292067  ...         0         0\n",
      "4     Card Payment   4226.073017  ...         1         0\n",
      "5              Fee   4521.677425  ...         1         0\n",
      "6     Loan Payment  12427.363429  ...         0         0\n",
      "7          Deposit   2573.447043  ...         0         1\n",
      "8          Deposit   5459.930052  ...         1         0\n",
      "9       Withdrawal   3161.141067  ...         1         0\n",
      "10    Card Payment   5569.700221  ...         0         1\n",
      "11    Loan Payment   9473.148645  ...         0         1\n",
      "12        Transfer  13470.434287  ...         1         0\n",
      "13    Loan Payment   1812.745805  ...         1         0\n",
      "14         Deposit    476.398154  ...         0         0\n",
      "\n",
      "[15 rows x 18 columns]\n",
      "Y_train [0 0 3 4 6 1 1 1 1 0]\n",
      "X_train after preprocessing: [[ 0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.76839331e+00 -1.69690321e-03  1.34835249e+00  2.36024194e-01\n",
      "   1.34875089e+00 -9.79232419e-01  1.45655867e+00  1.74322219e+00\n",
      "  -8.41829348e-01  1.18351134e+00  1.72744428e+00 -5.68112069e-01\n",
      "  -5.96270360e-01 -5.66132109e-01]]\n",
      "Top important features (by absolute coefficient):\n",
      "[2025-06-09 21:25:00,340: ERROR: 4071221513: An error occurred during model training: index 32 is out of bounds for axis 0 with size 7]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\RICH-FILES\\AppData\\Local\\Temp\\ipykernel_12860\\4071221513.py\", line 5, in <module>\n",
      "    model_trainer.train()\n",
      "  File \"C:\\Users\\RICH-FILES\\AppData\\Local\\Temp\\ipykernel_12860\\4034810082.py\", line 122, in train\n",
      "    print(f\"{feature_names[i]}: {importances[i]:.4f}\")\n",
      "IndexError: index 32 is out of bounds for axis 0 with size 7\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_training_config = config.get_model_training_config()\n",
    "    model_trainer = ModelTraining(config=model_training_config)\n",
    "    model_trainer.train()\n",
    "except Exception as e:\n",
    "    logger.exception(f\"An error occurred during model training: {e}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bankprod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
