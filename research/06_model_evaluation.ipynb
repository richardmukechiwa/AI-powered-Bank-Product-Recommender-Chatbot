{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a42ec141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\RICH-FILES\\\\Desktop\\\\ml\\\\AI-powered-Bank-Product-Recommender-Chatbot'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc54f688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\RICH-FILES\\\\Desktop\\\\ml'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0430e424",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = \"C:/Users/RICH-FILES/Desktop/ml/AI-powered-Bank-Product-Recommender-Chatbot\"\n",
    "os.chdir(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelEvaluationConfig:\n",
    "    root_dir: Path\n",
    "    test_data_path: Path\n",
    "    model_path: Path\n",
    "    metric_file_name: Path\n",
    "    target_column: str\n",
    "    params: dict[str, str]\n",
    "    grid_search_model_path: Path\n",
    "    \n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BankProducts.constants import *\n",
    "from BankProducts.utils.common  import read_yaml, create_directories\n",
    "from BankProducts   import logger\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    def get_model_evaluation_config(self) -> ModelEvaluationConfig:\n",
    "        config = self.config.model_evaluation   \n",
    "        params = self.params.random_forest\n",
    "        schema =  self.schema.target_column\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "        model_evaluation_config = ModelEvaluationConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            test_data_path=Path(config.test_data_path),\n",
    "            model_path=Path(config.model_path),\n",
    "            metric_file_name=Path(config.metric_file_name),\n",
    "            target_column=schema.name,\n",
    "            params=params,\n",
    "            grid_search_model_path= Path(config.grid_search_model_path)\n",
    "            \n",
    "            \n",
    "           \n",
    "            \n",
    "        )\n",
    "\n",
    "        return model_evaluation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e720637b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "import pandas as pd\n",
    "from BankProducts import logger\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import tempfile\n",
    "import mlflow\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from BankProducts.utils.common import save_json\n",
    "import numpy as np\n",
    "import shap\n",
    "from urllib.parse import urlparse\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='_distutils_hack')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluation:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "\n",
    "    def eval_metrics(self, actual, pred):\n",
    "        accuracy = accuracy_score(actual, pred)\n",
    "        precision = precision_score(actual, pred, average='weighted')\n",
    "        recall = recall_score(actual, pred, average='weighted')\n",
    "        f1 = f1_score(actual, pred, average='weighted')\n",
    "        return accuracy, precision, recall, f1\n",
    "\n",
    "    def log_confusion_matrix(self, actual, predicted, class_names):\n",
    "        cm = confusion_matrix(actual, predicted)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\",\n",
    "                    xticklabels=class_names, yticklabels=class_names)\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        temp_img_path = tempfile.NamedTemporaryFile(suffix=\".png\", delete=False).name\n",
    "        plt.savefig(temp_img_path)\n",
    "        plt.close()\n",
    "        mlflow.log_artifact(temp_img_path, artifact_path=\"confusion_matrix\")\n",
    "\n",
    "    def log_classification_report(self, actual, predicted, class_names):\n",
    "        report = classification_report(actual, predicted, target_names=class_names)\n",
    "        temp_txt_path = tempfile.NamedTemporaryFile(suffix=\".txt\", delete=False).name\n",
    "        with open(temp_txt_path, \"w\") as f:\n",
    "            f.write(report)\n",
    "        mlflow.log_artifact(temp_txt_path, artifact_path=\"bank_products_recommender\")\n",
    "\n",
    "    def log_into_mlflow(self):\n",
    "        test_data = pd.read_csv(self.config.test_data_path)\n",
    "        test_x = test_data.drop(columns=[self.config.target_column])\n",
    "        test_y = test_data[self.config.target_column]\n",
    "\n",
    "        # Encode the target variable\n",
    "        le = LabelEncoder()\n",
    "        test_y_encoded = le.fit_transform(test_y)\n",
    "\n",
    "        logger.info(\"Loading model from path: %s\", self.config.model_path)\n",
    "        pipeline = joblib.load(self.config.model_path)\n",
    "\n",
    "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "        mlflow.set_experiment(\"Product Recommender\")\n",
    "\n",
    "        if mlflow.active_run():\n",
    "            mlflow.end_run()\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            predicted = pipeline.predict(test_x)\n",
    "\n",
    "            accuracy, precision, recall, f1 = self.eval_metrics(test_y_encoded, predicted)\n",
    "\n",
    "            scores = {\n",
    "                \"model_name\": \"random_classifier\",\n",
    "                \"accuracy\": accuracy,\n",
    "                \"precision\": precision,\n",
    "                \"recall\": recall,\n",
    "                \"f1_score\": f1\n",
    "            }\n",
    "            \n",
    "            # Ensure directory exists\n",
    "            Path(self.config.metric_file_name).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            save_json(Path(self.config.metric_file_name), data=scores)\n",
    "            \n",
    "            logger.info(\"Metrics saved to: %s\", self.config.metric_file_name)\n",
    "            \n",
    "            logger.info(\"Logging accuracy\")\n",
    "            mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "            logger.info(\"Logging precision\")\n",
    "            mlflow.log_metric(\"precision\", precision)\n",
    "\n",
    "            logger.info(\"Logging recall\")\n",
    "            mlflow.log_metric(\"recall\", recall)\n",
    "\n",
    "            logger.info(\"Logging f1_score\")\n",
    "            mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "            logger.info(\"Setting class_names\")\n",
    "            class_names = le.classes_\n",
    "\n",
    "            logger.info(\"Logging confusion matrix\")\n",
    "            self.log_confusion_matrix(test_y_encoded, predicted, class_names)\n",
    "\n",
    "            logger.info(\"Logging classification report\")\n",
    "            self.log_classification_report(test_y_encoded, predicted, class_names)\n",
    "            \n",
    "            \n",
    "            logger.info(\"Tracking URI scheme: %s\", tracking_url_type_store)\n",
    "            logger.info(\"Tracking URI: %s\", mlflow.get_tracking_uri())\n",
    "\n",
    "\n",
    "            #if tracking_url_type_store != \"file\":\n",
    "                #mlflow.sklearn.log_model(pipeline, \"pipeline\", registered_model_name=\"product recommender\")\n",
    "            #else:\n",
    "                #mlflow.sklearn.log_model(pipeline, \"pipeline\")\n",
    "              \n",
    "            logger.info(\"mlflow model logged successfully.\")\n",
    "            \n",
    "\n",
    "    # perform a Grid Search to find the best model\n",
    "    def perform_grid_search(self):\n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "        from sklearn.pipeline import Pipeline\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "        from sklearn.compose import ColumnTransformer\n",
    "\n",
    "        # Load training data\n",
    "        test_data = pd.read_csv(self.config.test_data_path)\n",
    "        X_test = test_data.drop(columns=[self.config.target_column])\n",
    "        y_test = test_data[self.config.target_column]\n",
    "\n",
    "        # Define preprocessing steps\n",
    "        numeric_features = X_test.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "        categorical_features = X_test.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', StandardScaler(), numeric_features),\n",
    "                ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "            ])\n",
    "\n",
    "        # Define the model\n",
    "        model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "        # Create a pipeline\n",
    "        pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])\n",
    "\n",
    "        # Define hyperparameter grid\n",
    "        param_grid = {\n",
    "            'classifier__n_estimators': [50, 100, 200],\n",
    "            'classifier__max_depth': [None, 10, 20],\n",
    "            'classifier__min_samples_split': [2, 5, 10],\n",
    "            #'classifier_criterion': ['gini', 'entropy'],\n",
    "            'classifier__max_features': ['sqrt', 'log2'], \n",
    "            'classifier__min_samples_leaf': [1, 2, 4],\n",
    "            'classifier__class_weight': ['balanced', None],\n",
    "            'classifier__n_jobs': [-1]  # Use all available cores\n",
    "            \n",
    "        }\n",
    "            \n",
    "        # Perform grid search with cross-validation\n",
    "        grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "        grid_search.fit(X_test, y_test)\n",
    "\n",
    "        logger.info(\"Best parameters found: %s\", grid_search.best_params_)\n",
    "        \n",
    "        # Save the best model\n",
    "        joblib.dump(grid_search.best_estimator_, self.config.grid_search_model_path)\n",
    "        \n",
    "        logger.info(\"Best model saved to: %s\", self.config.grid_search_model_path) \n",
    "        \n",
    "        #extract feature_importances\n",
    "        feature_importances = grid_search.best_estimator_.named_steps['classifier'].feature_importances_\n",
    "        feature_importances_df = pd.DataFrame({'feature': X_test.columns, 'importance': feature_importances})\n",
    "        \n",
    "        return feature_importances_df\n",
    "\n",
    "                                                                    \n",
    "    \n",
    "    \n",
    "    # perform validation using cross validation\n",
    "    def validate_model(self):\n",
    "        test_data = pd.read_csv(self.config.test_data_path)\n",
    "        test_x = test_data.drop(columns=[self.config.target_column])\n",
    "        test_y = test_data[self.config.target_column]\n",
    "\n",
    "        pipeline = joblib.load(self.config.model_path)\n",
    "\n",
    "        # Perform cross-validation\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "        scores = cross_val_score(pipeline, test_x, test_y, cv=5, scoring='accuracy')\n",
    "\n",
    "        logger.info(\"Cross-validation scores: %s\", scores)\n",
    "        logger.info(\"Mean cross-validation score: %.2f\", scores.mean())\n",
    "\n",
    "        return scores.mean()\n",
    "            \n",
    "    \n",
    "        \n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-26 22:36:32,730: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-05-26 22:36:32,735: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-05-26 22:36:32,740: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2025-05-26 22:36:32,742: INFO: common: created directory at: artifacts]\n",
      "[2025-05-26 22:36:32,744: INFO: common: created directory at: artifacts]\n",
      "[2025-05-26 22:36:32,770: INFO: 1019718506: Loading model from path: artifacts\\model_training\\model.joblib]\n",
      "[2025-05-26 22:36:33,337: INFO: common: json file saved at: artifacts\\model_evaluation\\metrics.json]\n",
      "[2025-05-26 22:36:33,339: INFO: 1019718506: Metrics saved to: artifacts\\model_evaluation\\metrics.json]\n",
      "[2025-05-26 22:36:33,339: INFO: 1019718506: Logging accuracy]\n",
      "[2025-05-26 22:36:33,345: INFO: 1019718506: Logging precision]\n",
      "[2025-05-26 22:36:33,350: INFO: 1019718506: Logging recall]\n",
      "[2025-05-26 22:36:33,355: INFO: 1019718506: Logging f1_score]\n",
      "[2025-05-26 22:36:33,361: INFO: 1019718506: Setting class_names]\n",
      "[2025-05-26 22:36:33,362: INFO: 1019718506: Logging confusion matrix]\n",
      "[2025-05-26 22:36:33,636: INFO: 1019718506: Logging classification report]\n",
      "[2025-05-26 22:36:33,650: INFO: 1019718506: Tracking URI scheme: file]\n",
      "[2025-05-26 22:36:33,651: INFO: 1019718506: Tracking URI: file:///C:/Users/RICH-FILES/Desktop/ml/AI-powered-Bank-Product-Recommender-Chatbot/mlruns]\n",
      "[2025-05-26 22:36:33,652: INFO: 1019718506: mlflow model logged successfully.]\n",
      "[2025-05-26 22:36:36,790: INFO: 1019718506: Cross-validation scores: [0.19736842 0.25       0.18421053 0.22516556 0.19205298]]\n",
      "[2025-05-26 22:36:36,792: INFO: 1019718506: Mean cross-validation score: 0.21]\n",
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
      "[2025-05-26 22:43:10,868: INFO: 1019718506: Best parameters found: {'classifier__class_weight': 'balanced', 'classifier__max_depth': 10, 'classifier__max_features': 'sqrt', 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 50, 'classifier__n_jobs': -1}]\n",
      "[2025-05-26 22:43:10,895: INFO: 1019718506: Best model saved to: artifacts\\model_training\\grid_search_model.joblib]\n",
      "An error occurred: All arrays must be of the same length\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_evaluation_config = config.get_model_evaluation_config()\n",
    "    eval = ModelEvaluation(config=model_evaluation_config)\n",
    "    eval.log_into_mlflow()\n",
    "    eval.validate_model()\n",
    "    #eval.feature_importance()\n",
    "    eval.perform_grid_search()  \n",
    "    \n",
    "    \n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9469ccb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6710aab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19386016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaa7a66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea8dca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55592b65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc40b527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06341f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bankprod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
