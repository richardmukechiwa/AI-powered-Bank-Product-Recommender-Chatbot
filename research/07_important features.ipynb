{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1cf18cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c41edd58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\RICH-FILES\\\\Desktop\\\\ml\\\\AI-powered-Bank-Product-Recommender-Chatbot'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3caec5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7c5d1f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\RICH-FILES\\\\Desktop\\\\ml'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "99f58a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = \"C:/Users/RICH-FILES/Desktop/ml/AI-powered-Bank-Product-Recommender-Chatbot\"\n",
    "os.chdir(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "04d2c621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class FeatureImportanceConfig:\n",
    "    \"\"\"Configuration for feature importance analysis.\n",
    "    \"\"\"\n",
    "    root_dir: Path\n",
    "    grid_search_model: Path\n",
    "    training_data_path: Path\n",
    "    test_data_path: Path\n",
    "    feature_importance_file: Path\n",
    "    target_column: str\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a0b6cceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BankProducts.constants import *\n",
    "from BankProducts.utils.common import read_yaml, create_directories\n",
    "from BankProducts import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9753d58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "        \n",
    "    def get_feature_importance_config(self) -> FeatureImportanceConfig:\n",
    "        config = self.config.feature_importance \n",
    "        schema = self.schema.target_column\n",
    "        params= self.params\n",
    "        \n",
    "        create_directories([self.config.artifacts_root])\n",
    "       \n",
    "        \n",
    "        feature_importance_config = FeatureImportanceConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            grid_search_model=Path(config.grid_search_model),\n",
    "            training_data_path=Path(config.training_data_path),\n",
    "            test_data_path=Path(config.test_data_path),\n",
    "            feature_importance_file=Path(config.feature_importance_file),\n",
    "            target_column= schema.name\n",
    "            \n",
    "        )\n",
    "        logger.info(f\"Feature Importance Config: {feature_importance_config}\")\n",
    "        return feature_importance_config\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f0ad2645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "419ab903",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureImportance:\n",
    "    def __init__(self, config: FeatureImportanceConfig):\n",
    "        self.config = config\n",
    "        self.pipeline = None\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.processor = None\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Load training and test data.\"\"\"\n",
    "        self.X_train = pd.read_csv(self.config.training_data_path)\n",
    "        self.X_test = pd.read_csv(self.config.test_data_path)\n",
    "        logger.info(\"Data loaded successfully.\")\n",
    "        \n",
    "        \n",
    "    def load_model(self):\n",
    "        import joblib\n",
    "        import logging\n",
    "        logger = logging.getLogger(__name__)\n",
    "\n",
    "        # Load pipeline\n",
    "        self.pipeline = joblib.load(self.config.grid_search_model)\n",
    "\n",
    "        # Extract steps\n",
    "        self.model = self.pipeline.named_steps['classifier']\n",
    "        self.processor = self.pipeline.named_steps['preprocessor']\n",
    "\n",
    "        # Transform training data\n",
    "        X_transformed = self.processor.transform(self.X_train)\n",
    "        if hasattr(X_transformed, \"toarray\"):\n",
    "            self.X_train = X_transformed.toarray()\n",
    "        else:\n",
    "            self.X_train = X_transformed\n",
    "\n",
    "        # Get feature names\n",
    "        self.feature_names = self.processor.get_feature_names_out()\n",
    "\n",
    "        logger.info(\"Model loaded successfully.\")\n",
    "\n",
    "    def shap_analysis(self, top_n: int = 20):\n",
    "        import shap\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        explainer = shap.TreeExplainer(self.model)\n",
    "        shap_values = explainer.shap_values(self.X_train)\n",
    "\n",
    "        # Handle multiclass SHAP values\n",
    "        if isinstance(shap_values, list):\n",
    "            # Multiclass: average SHAP across classes\n",
    "            shap_array = np.array([np.abs(class_shap).mean(axis=0) for class_shap in shap_values])  # shape: (n_classes, n_features)\n",
    "            shap_values_mean = shap_array.mean(axis=0)  # shape: (n_features,)\n",
    "            # For plotting, use class 0 or sum over all\n",
    "            plot_values = shap_values[0]  # you can also use np.mean(shap_values, axis=0)\n",
    "        else:\n",
    "            # Binary classification or regression\n",
    "            shap_values_mean = np.abs(shap_values).mean(axis=0)\n",
    "            plot_values = shap_values\n",
    "\n",
    "        feature_importance = pd.Series(shap_values_mean, index=self.feature_names).sort_values(ascending=False)\n",
    "\n",
    "        logger.info(f\"Top {top_n} important features by SHAP values:\")\n",
    "        for i, (feature, score) in enumerate(feature_importance.head(top_n).items(), start=1):\n",
    "            logger.info(f\"{i}. {feature}: {score:.4f}\")\n",
    "\n",
    "        # SHAP summary plot\n",
    "        shap.summary_plot(plot_values, self.X_train, feature_names=self.feature_names, show=False)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"artifacts/feature_importance/shap_summary_plot.png\", dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        # Bar chart for top N\n",
    "        top_features = feature_importance.head(top_n)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        top_features.plot(kind=\"barh\", color=\"skyblue\")\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.title(f\"Top {top_n} SHAP Feature Importances\")\n",
    "        plt.xlabel(\"Mean |SHAP value|\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"artifacts/feature_importance/shap_top_features_bar.png\", dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        return feature_importance\n",
    "    \n",
    "    \n",
    "    def feature_importance(self):\n",
    "        import joblib  # Fix: import joblib\n",
    "        import shap\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        \n",
    "        \n",
    "        test_data = pd.read_csv(self.config.test_data_path)\n",
    "        \n",
    "        test_x = test_data.drop(self.config.target_column, axis=1)\n",
    "        \n",
    "        # change the month column to string\n",
    "        #test_x['month'] = test_x['month'].astype('str')\n",
    "        \n",
    "        \n",
    "        pipeline = joblib.load(self.config.grid_search_model)\n",
    "        \n",
    "         # Extract preprocessor and model from pipeline\n",
    "        preprocessor = pipeline.named_steps['preprocessor']\n",
    "        model = pipeline.named_steps['classifier']\n",
    "\n",
    "        # Transform test data using preprocessor\n",
    "        X_processed = preprocessor.transform(test_x)\n",
    "\n",
    "        # Get feature names after preprocessing\n",
    "        try:\n",
    "            feature_names = preprocessor.get_feature_names_out()\n",
    "        except AttributeError:\n",
    "            num_features = preprocessor.transformers_[0][2]\n",
    "            cat_encoder = preprocessor.transformers_[1][1]\n",
    "            cat_features = cat_encoder.get_feature_names_out(preprocessor.transformers_[1][2])\n",
    "            feature_names = np.concatenate([num_features, cat_features])\n",
    "\n",
    "        # Convert processed features to DataFrame\n",
    "        X_df = pd.DataFrame(\n",
    "            X_processed.toarray() if hasattr(X_processed, 'toarray') else X_processed,\n",
    "            columns=feature_names\n",
    "        )\n",
    "        \n",
    "        print(X_df.columns)\n",
    "        \n",
    "         \n",
    "        \n",
    "        # Create SHAP explainer and compute SHAP values\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        shap_values = explainer.shap_values(X_df)\n",
    "\n",
    "        # Generate SHAP plot\n",
    "        shap.summary_plot(shap_values, X_df, show=False)\n",
    "        #buf = BytesIO()\n",
    "        #plt.savefig(buf, format=\"png\", bbox_inches='tight')\n",
    "        #plt.close()\n",
    "        #buf.seek(0)\n",
    "\n",
    "        # Encode image to base64\n",
    "        #img_base64 = base64.b64encode(buf.getvalue()).decode('utf-8')\n",
    "        #return img_base64\n",
    "        \n",
    "        # For regression or binary classification\n",
    "        shap_df = pd.DataFrame(shap_values, columns=X_df.columns)\n",
    "        shap_abs_mean = shap_df.abs().mean().sort_values(ascending=False)\n",
    "\n",
    "\n",
    "        # 6. Select top N important features\n",
    "        top_n = 10  # You can change this to any number or use a threshold\n",
    "        top_features = shap_abs_mean.head(top_n).index.tolist()\n",
    "\n",
    "        print(\"Top Important Features:\")\n",
    "        print(top_features)\n",
    "        \n",
    "        \n",
    "    def feature_importances(self):\n",
    "        import joblib\n",
    "        import shap\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import matplotlib.pyplot as plt\n",
    "        import os\n",
    "\n",
    "        test_data = pd.read_csv(self.config.test_data_path)\n",
    "        test_x = test_data.drop(self.config.target_column, axis=1)\n",
    "\n",
    "        pipeline = joblib.load(self.config.grid_search_model)\n",
    "\n",
    "        preprocessor = pipeline.named_steps['preprocessor']\n",
    "        model = pipeline.named_steps['classifier']\n",
    "\n",
    "        # Transform test data using preprocessor\n",
    "        X_processed = preprocessor.transform(test_x)\n",
    "\n",
    "        # Get feature names after preprocessing\n",
    "        try:\n",
    "            feature_names = preprocessor.get_feature_names_out()\n",
    "        except AttributeError:\n",
    "            num_features = preprocessor.transformers_[0][2]\n",
    "            cat_encoder = preprocessor.transformers_[1][1]\n",
    "            cat_features = cat_encoder.get_feature_names_out(preprocessor.transformers_[1][2])\n",
    "            feature_names = np.concatenate([num_features, cat_features])\n",
    "\n",
    "        X_df = pd.DataFrame(\n",
    "            X_processed.toarray() if hasattr(X_processed, 'toarray') else X_processed,\n",
    "            columns=feature_names\n",
    "        )\n",
    "\n",
    "        print(X_df.columns)\n",
    "\n",
    "        # Create SHAP explainer\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        shap_values = explainer.shap_values(X_df)\n",
    "\n",
    "        # Handle multiclass vs binary/regression\n",
    "        if isinstance(shap_values, list) and isinstance(shap_values[0], np.ndarray):\n",
    "            # Multiclass classification (shap_values is a list of arrays)\n",
    "            print(\"Multiclass classification detected.\")\n",
    "            \n",
    "            # Average absolute SHAP values across all classes\n",
    "            shap_array = np.abs(np.array(shap_values))  # shape: (n_classes, n_samples, n_features)\n",
    "            shap_mean = shap_array.mean(axis=0)         # shape: (n_samples, n_features)\n",
    "            shap_df = pd.DataFrame(shap_mean, columns=X_df.columns)\n",
    "\n",
    "            # Optional: Save summary plots for each class\n",
    "            for i, class_shap in enumerate(shap_values):\n",
    "                shap.summary_plot(class_shap, X_df, show=False)\n",
    "                plt.title(f\"SHAP Summary - Class {i}\")\n",
    "                plt.savefig(f\"{self.config.feature_importance_file.stem}_class_{i}.png\", bbox_inches='tight')\n",
    "                plt.close()\n",
    "\n",
    "        else:\n",
    "            # Binary classification or regression\n",
    "            print(\"Binary classification or regression detected.\")\n",
    "            shap_df = pd.DataFrame(shap_values, columns=X_df.columns)\n",
    "\n",
    "            shap.summary_plot(shap_values, X_df, show=False)\n",
    "            plt.savefig(f\"{self.config.feature_importance_file.stem}.png\", bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "        # Compute mean absolute SHAP values\n",
    "        shap_abs_mean = shap_df.abs().mean().sort_values(ascending=False)\n",
    "\n",
    "        # Select top N important features\n",
    "        top_n = 10\n",
    "        top_features = shap_abs_mean.head(top_n).index.tolist()\n",
    "\n",
    "        print(\"Top Important Features:\")\n",
    "        print(top_features)\n",
    "\n",
    "        # Save to JSON\n",
    "        os.makedirs(self.config.feature_importance_file.parent, exist_ok=True)\n",
    "        shap_abs_mean.to_json(self.config.feature_importance_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "60c1ff6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-27 21:42:44,900: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-05-27 21:42:44,907: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-05-27 21:42:44,911: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2025-05-27 21:42:44,912: INFO: common: created directory at: artifacts]\n",
      "[2025-05-27 21:42:44,913: INFO: common: created directory at: artifacts]\n",
      "[2025-05-27 21:42:44,914: INFO: 1520614144: Feature Importance Config: FeatureImportanceConfig(root_dir=WindowsPath('artifacts/feature_importance'), grid_search_model=WindowsPath('artifacts/model_training/grid_search_model.joblib'), training_data_path=WindowsPath('artifacts/data_transformation/train_data.csv'), test_data_path=WindowsPath('artifacts/data_transformation/test_data.csv'), feature_importance_file=WindowsPath('artifacts/feature_importance/feature_importance.json'), target_column='product_name')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['num__age', 'num__annual_income', 'num__credit_score',\n",
      "       'cat__gender_Female', 'cat__gender_Male',\n",
      "       'cat__occupation_Academic librarian',\n",
      "       'cat__occupation_Accommodation manager',\n",
      "       'cat__occupation_Accountant, chartered',\n",
      "       'cat__occupation_Accountant, chartered certified',\n",
      "       'cat__occupation_Accountant, chartered public finance',\n",
      "       ...\n",
      "       'cat__occupation_Water quality scientist',\n",
      "       'cat__occupation_Web designer', 'cat__marital_status_Divorced',\n",
      "       'cat__marital_status_Married', 'cat__marital_status_Single',\n",
      "       'cat__financial_goals_Education', 'cat__financial_goals_Home Ownership',\n",
      "       'cat__financial_goals_Retirement', 'cat__financial_goals_Savings',\n",
      "       'cat__financial_goals_Travel'],\n",
      "      dtype='object', length=464)\n",
      "Binary classification or regression detected.\n",
      "[2025-05-27 21:42:45,522: ERROR: 2208610099: An error occurred: Must pass 2-d input. shape=(758, 464, 5)]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\RICH-FILES\\AppData\\Local\\Temp\\ipykernel_2452\\2208610099.py\", line 5, in <module>\n",
      "    feature_imp.feature_importances()\n",
      "  File \"C:\\Users\\RICH-FILES\\AppData\\Local\\Temp\\ipykernel_2452\\610735107.py\", line 221, in feature_importances\n",
      "    shap_df = pd.DataFrame(shap_values, columns=X_df.columns)\n",
      "  File \"c:\\Users\\RICH-FILES\\anacoda4\\envs\\bankprod\\lib\\site-packages\\pandas\\core\\frame.py\", line 827, in __init__\n",
      "    mgr = ndarray_to_mgr(\n",
      "  File \"c:\\Users\\RICH-FILES\\anacoda4\\envs\\bankprod\\lib\\site-packages\\pandas\\core\\internals\\construction.py\", line 314, in ndarray_to_mgr\n",
      "    values = _ensure_2d(values)\n",
      "  File \"c:\\Users\\RICH-FILES\\anacoda4\\envs\\bankprod\\lib\\site-packages\\pandas\\core\\internals\\construction.py\", line 592, in _ensure_2d\n",
      "    raise ValueError(f\"Must pass 2-d input. shape={values.shape}\")\n",
      "ValueError: Must pass 2-d input. shape=(758, 464, 5)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must pass 2-d input. shape=(758, 464, 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[155], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     15\u001b[0m     logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e \n",
      "Cell \u001b[1;32mIn[155], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m feature_importance_config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_feature_importance_config()\n\u001b[0;32m      4\u001b[0m feature_imp \u001b[38;5;241m=\u001b[39m FeatureImportance(config \u001b[38;5;241m=\u001b[39m feature_importance_config)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mfeature_imp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_importances\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#feature_imp.load_model()\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#feature_importance = feature_imp.shap_analysis()\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Save as CSV or JSON depending on your config\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#feature_importance_df.columns = ['feature', 'importance']\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#feature_importance_df.to_csv(feature_importance_config.feature_importance_file, index=False)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature importance saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeature_importance_config\u001b[38;5;241m.\u001b[39mfeature_importance_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[154], line 221\u001b[0m, in \u001b[0;36mFeatureImportance.feature_importances\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# Binary classification or regression\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBinary classification or regression detected.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 221\u001b[0m     shap_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshap_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m     shap\u001b[38;5;241m.\u001b[39msummary_plot(shap_values, X_df, show\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    224\u001b[0m     plt\u001b[38;5;241m.\u001b[39msavefig(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mfeature_importance_file\u001b[38;5;241m.\u001b[39mstem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m, bbox_inches\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\RICH-FILES\\anacoda4\\envs\\bankprod\\lib\\site-packages\\pandas\\core\\frame.py:827\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    816\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    817\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    818\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    824\u001b[0m             copy\u001b[38;5;241m=\u001b[39m_copy,\n\u001b[0;32m    825\u001b[0m         )\n\u001b[0;32m    826\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 827\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32mc:\\Users\\RICH-FILES\\anacoda4\\envs\\bankprod\\lib\\site-packages\\pandas\\core\\internals\\construction.py:314\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    308\u001b[0m     _copy \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    309\u001b[0m         copy_on_sanitize\n\u001b[0;32m    310\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, dtype))\n\u001b[0;32m    311\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    312\u001b[0m     )\n\u001b[0;32m    313\u001b[0m     values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(values, copy\u001b[38;5;241m=\u001b[39m_copy)\n\u001b[1;32m--> 314\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;66;03m# by definition an array here\u001b[39;00m\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;66;03m# the dtypes will be coerced to a single dtype\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     values \u001b[38;5;241m=\u001b[39m _prep_ndarraylike(values, copy\u001b[38;5;241m=\u001b[39mcopy_on_sanitize)\n",
      "File \u001b[1;32mc:\\Users\\RICH-FILES\\anacoda4\\envs\\bankprod\\lib\\site-packages\\pandas\\core\\internals\\construction.py:592\u001b[0m, in \u001b[0;36m_ensure_2d\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m    590\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mreshape((values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust pass 2-d input. shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalues\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "\u001b[1;31mValueError\u001b[0m: Must pass 2-d input. shape=(758, 464, 5)"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    feature_importance_config = config.get_feature_importance_config()\n",
    "    feature_imp = FeatureImportance(config = feature_importance_config)\n",
    "    feature_imp.feature_importances()\n",
    "    #feature_imp.load_model()\n",
    "    #feature_importance = feature_imp.shap_analysis()\n",
    "    # Save as CSV or JSON depending on your config\n",
    "    # Convert Series to DataFrame before saving\n",
    "    #feature_importance_df = feature_importance.reset_index()\n",
    "    #feature_importance_df.columns = ['feature', 'importance']\n",
    "    #feature_importance_df.to_csv(feature_importance_config.feature_importance_file, index=False)\n",
    "    logger.info(f\"Feature importance saved to {feature_importance_config.feature_importance_file}\")\n",
    "except Exception as e:\n",
    "    logger.exception(f\"An error occurred: {e}\")\n",
    "    raise e \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846d8a33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6211c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ec6934",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bankprod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
