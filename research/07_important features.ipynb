{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1cf18cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c41edd58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\RICH-FILES\\\\Desktop\\\\ml\\\\AI-powered-Bank-Product-Recommender-Chatbot'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3caec5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7c5d1f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\RICH-FILES\\\\Desktop\\\\ml'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "99f58a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = \"C:/Users/RICH-FILES/Desktop/ml/AI-powered-Bank-Product-Recommender-Chatbot\"\n",
    "os.chdir(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "04d2c621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class FeatureImportanceConfig:\n",
    "    \"\"\"Configuration for feature importance analysis.\n",
    "    \"\"\"\n",
    "    root_dir: Path\n",
    "    grid_search_model: Path\n",
    "    training_data_path: Path\n",
    "    test_data_path: Path\n",
    "    feature_importance_file: Path\n",
    "    target_column: str\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a0b6cceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BankProducts.constants import *\n",
    "from BankProducts.utils.common import read_yaml, create_directories\n",
    "from BankProducts import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9753d58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "        \n",
    "    def get_feature_importance_config(self) -> FeatureImportanceConfig:\n",
    "        config = self.config.feature_importance \n",
    "        schema = self.schema.target_column\n",
    "        params= self.params\n",
    "        \n",
    "        create_directories([self.config.artifacts_root])\n",
    "       \n",
    "        \n",
    "        feature_importance_config = FeatureImportanceConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            grid_search_model=Path(config.grid_search_model),\n",
    "            training_data_path=Path(config.training_data_path),\n",
    "            test_data_path=Path(config.test_data_path),\n",
    "            feature_importance_file=Path(config.feature_importance_file),\n",
    "            target_column= schema.name\n",
    "            \n",
    "        )\n",
    "        logger.info(f\"Feature Importance Config: {feature_importance_config}\")\n",
    "        return feature_importance_config\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f0ad2645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "419ab903",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureImportance:\n",
    "    def __init__(self, config: FeatureImportanceConfig):\n",
    "        self.config = config\n",
    "        self.pipeline = None\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.processor = None\n",
    "\n",
    "    def important_features(self):\n",
    "        import joblib\n",
    "        import shap\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        import matplotlib.pyplot as plt\n",
    "        import os\n",
    "        \n",
    "        logger.info(\"Important Features\")\n",
    "\n",
    "        test_data = pd.read_csv(self.config.test_data_path)\n",
    "        test_x = test_data.drop(self.config.target_column, axis=1)\n",
    "\n",
    "        pipeline = joblib.load(self.config.grid_search_model)\n",
    "\n",
    "        preprocessor = pipeline.named_steps['preprocessor']\n",
    "        model = pipeline.named_steps['classifier']\n",
    "\n",
    "        # Transform test data using preprocessor\n",
    "        X_processed = preprocessor.transform(test_x)\n",
    "\n",
    "        # Get feature names after preprocessing\n",
    "        try:\n",
    "            feature_names = preprocessor.get_feature_names_out()\n",
    "        except AttributeError:\n",
    "            num_features = preprocessor.transformers_[0][2]\n",
    "            cat_encoder = preprocessor.transformers_[1][1]\n",
    "            cat_features = cat_encoder.get_feature_names_out(preprocessor.transformers_[1][2])\n",
    "            feature_names = np.concatenate([num_features, cat_features])\n",
    "\n",
    "        X_df = pd.DataFrame(\n",
    "            X_processed.toarray() if hasattr(X_processed, 'toarray') else X_processed,\n",
    "            columns=feature_names\n",
    "        )\n",
    "\n",
    "        print(X_df.columns)\n",
    "\n",
    "        # Create SHAP explainer\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        shap_values = explainer.shap_values(X_df)\n",
    "\n",
    "        # Handle multiclass vs binary/regression\n",
    "        if isinstance(shap_values, list) and isinstance(shap_values[0], np.ndarray):\n",
    "            # Multiclass classification (shap_values is a list of arrays)\n",
    "            print(\"Multiclass classification detected.\")\n",
    "            \n",
    "            # Average absolute SHAP values across all classes\n",
    "            shap_array = np.abs(np.array(shap_values))  # shape: (n_classes, n_samples, n_features)\n",
    "            shap_mean = shap_array.mean(axis=0)         # shape: (n_samples, n_features)\n",
    "            shap_df = pd.DataFrame(shap_mean, columns=X_df.columns)\n",
    "\n",
    "            # Optional: Save summary plots for each class\n",
    "            for i, class_shap in enumerate(shap_values):\n",
    "                shap.summary_plot(class_shap, X_df, show=False)\n",
    "                plt.title(f\"SHAP Summary - Class {i}\")\n",
    "                plt.savefig(f\"{self.config.feature_importance_file.stem}_class_{i}.png\", bbox_inches='tight')\n",
    "                plt.close()\n",
    "\n",
    "        else:\n",
    "            # Binary classification or regression\n",
    "            print(\"Binary classification or regression detected.\")\n",
    "            shap_df = pd.DataFrame(shap_values, columns=X_df.columns)\n",
    "\n",
    "            shap.summary_plot(shap_values, X_df, show=False)\n",
    "            plt.savefig(f\"{self.config.feature_importance_file.stem}.png\", bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "        # Compute mean absolute SHAP values\n",
    "        shap_abs_mean = shap_df.abs().mean().sort_values(ascending=False)\n",
    "\n",
    "        # Select top N important features\n",
    "        top_n = 10\n",
    "        top_features = shap_abs_mean.head(top_n).index.tolist()\n",
    "\n",
    "        print(\"Top Important Features:\")\n",
    "        print(top_features)\n",
    "\n",
    "        # Save to JSON\n",
    "        os.makedirs(self.config.feature_importance_file.parent, exist_ok=True)\n",
    "        shap_abs_mean.to_json(self.config.feature_importance_file)\n",
    "\n",
    "    def important_feature(self):\n",
    "        \n",
    "        \"\"\"Compute and save SHAP feature importance for the model.\"\"\"\n",
    "        # Compute feature importances robustly for multiclass\n",
    "        \n",
    "        logger.info(\"Important Feature search\")\n",
    "        import joblib\n",
    "        import shap\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "\n",
    "        test_data = pd.read_csv(self.config.test_data_path)\n",
    "        test_x = test_data.drop(self.config.target_column, axis=1)\n",
    "\n",
    "        pipeline = joblib.load(self.config.grid_search_model)\n",
    "        preprocessor = pipeline.named_steps['preprocessor']\n",
    "        model = pipeline.named_steps['classifier']\n",
    "\n",
    "        X_processed = preprocessor.transform(test_x)\n",
    "        try:\n",
    "            feature_names = preprocessor.get_feature_names_out()\n",
    "        except AttributeError:\n",
    "            num_features = preprocessor.transformers_[0][2]\n",
    "            cat_encoder = preprocessor.transformers_[1][1]\n",
    "            cat_features = cat_encoder.get_feature_names_out(preprocessor.transformers_[1][2])\n",
    "            feature_names = np.concatenate([num_features, cat_features])\n",
    "\n",
    "        X_df = pd.DataFrame(\n",
    "            X_processed.toarray() if hasattr(X_processed, 'toarray') else X_processed,\n",
    "            columns=feature_names\n",
    "        )\n",
    "\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        shap_values = explainer.shap_values(X_df)\n",
    "\n",
    "        # Handle multiclass\n",
    "        if isinstance(shap_values, np.ndarray) and shap_values.ndim == 3:\n",
    "            # shape: (n_samples, n_features, n_classes)\n",
    "            # Take mean absolute SHAP value across classes for each feature\n",
    "            shap_abs = np.abs(shap_values).mean(axis=2)  # shape: (n_samples, n_features)\n",
    "            shap_df = pd.DataFrame(shap_abs, columns=X_df.columns)\n",
    "            shap_importance = shap_df.mean().sort_values(ascending=False)\n",
    "        elif isinstance(shap_values, list) and isinstance(shap_values[0], np.ndarray):\n",
    "            # shape: (n_classes, n_samples, n_features)\n",
    "            shap_array = np.abs(np.array(shap_values))  # (n_classes, n_samples, n_features)\n",
    "            shap_abs = shap_array.mean(axis=0)  # mean over classes -> (n_samples, n_features)\n",
    "            shap_df = pd.DataFrame(shap_abs, columns=X_df.columns)\n",
    "            shap_importance = shap_df.mean().sort_values(ascending=False)\n",
    "        else:\n",
    "            shap_df = pd.DataFrame(shap_values, columns=X_df.columns)\n",
    "            shap_importance = shap_df.abs().mean().sort_values(ascending=False)\n",
    "\n",
    "        # Print top important features\n",
    "        \n",
    "        print(\"Top Important Features:\")\n",
    "        print(shap_importance.head(10))\n",
    "\n",
    "        # Optionally save to JSON\n",
    "        import os\n",
    "        os.makedirs(self.config.feature_importance_file.parent, exist_ok=True)\n",
    "        shap_importance.to_json(self.config.feature_importance_file)\n",
    "\n",
    "        logger.info(f\"Feature importance saved to {self.config.feature_importance_file}\")\n",
    "        return shap_importance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "60c1ff6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-09 00:12:24,750: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-06-09 00:12:24,754: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-06-09 00:12:24,761: INFO: common: yaml file: schema.yaml loaded successfully]\n",
      "[2025-06-09 00:12:24,764: INFO: common: created directory at: artifacts]\n",
      "[2025-06-09 00:12:24,766: INFO: common: created directory at: artifacts]\n",
      "[2025-06-09 00:12:24,768: INFO: 1520614144: Feature Importance Config: FeatureImportanceConfig(root_dir=WindowsPath('artifacts/feature_importance'), grid_search_model=WindowsPath('artifacts/model_training/grid_search_model.joblib'), training_data_path=WindowsPath('artifacts/data_transformation/train_data.csv'), test_data_path=WindowsPath('artifacts/data_transformation/test_data.csv'), feature_importance_file=WindowsPath('artifacts/feature_importance/feature_importance.json'), target_column='recommendedoffer')]\n",
      "[2025-06-09 00:12:24,769: INFO: 1596762816: Feature Importance Config: FeatureImportanceConfig(root_dir=WindowsPath('artifacts/feature_importance'), grid_search_model=WindowsPath('artifacts/model_training/grid_search_model.joblib'), training_data_path=WindowsPath('artifacts/data_transformation/train_data.csv'), test_data_path=WindowsPath('artifacts/data_transformation/test_data.csv'), feature_importance_file=WindowsPath('artifacts/feature_importance/feature_importance.json'), target_column='recommendedoffer')]\n",
      "[2025-06-09 00:12:24,771: INFO: 1475621309: Important Feature search]\n",
      "Top Important Features:\n",
      "num__monthlyincome                            0.056649\n",
      "cat__customersegment_Middle Income Segment    0.055245\n",
      "cat__customersegment_High Income Segment      0.049398\n",
      "cat__productcategory_Credit Card              0.048558\n",
      "cat__productcategory_Loan                     0.046050\n",
      "cat__productcategory_Savings Account          0.042629\n",
      "cat__customersegment_Low Income Segment       0.042148\n",
      "cat__productcategory_Mortgage                 0.023166\n",
      "cat__productcategory_Checking Account         0.021631\n",
      "num__amount                                   0.010055\n",
      "dtype: float64\n",
      "[2025-06-09 00:13:21,589: INFO: 1475621309: Feature importance saved to artifacts\\feature_importance\\feature_importance.json]\n",
      "[2025-06-09 00:13:21,593: INFO: 1596762816: Feature importance saved to artifacts\\feature_importance\\feature_importance.json]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    feature_importance_config = config.get_feature_importance_config()\n",
    "    feature_imp = FeatureImportance(config = feature_importance_config)\n",
    "    logger.info(f\"Feature Importance Config: {feature_importance_config}\")\n",
    "    #feature_imp.important_features()\n",
    "    feature_imp.important_feature()\n",
    "    \n",
    "    logger.info(f\"Feature importance saved to {feature_importance_config.feature_importance_file}\")\n",
    "except Exception as e:\n",
    "    logger.exception(f\"An error occurred: {e}\")\n",
    "    raise e \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846d8a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"customersegment\", \"product_category\", \"amount\", \"monthlyincome\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6211c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ec6934",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bankprod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
